{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "875eecbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "aff4e714",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_df =  pd.read_csv(\n",
    "    'data/01_data_cruda/MI_data.csv', \n",
    "    header=0, \n",
    "    sep=\",\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9e254c",
   "metadata": {},
   "source": [
    "There  are  four  possible  time  moments  for  complication  prediction:  on  base  of  the information known at\n",
    "\n",
    "1.the time of admission to hospital:all input columns (2-112) except 93, 94, 95, 100, 101, 102, 103, 104, 105can be usedfor prediction;\n",
    "\n",
    "2.the end of the first day(24 hours after admission to the hospital):all input columns (2-112) except 94, 95, 101, 102, 104, 105 can be usedfor prediction;\n",
    "\n",
    "3.the end of the second day (48 hours after admission to the hospital) all input columns (2-112) except 95, 102, 105 can be usedfor prediction;\n",
    "\n",
    "4.the end of the third day (72 hours after admission to the hospital) all input columns (2-112) can be usedfor prediction.\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4ee27d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos referencia a las columnas 2-112 (Variables que pueden ser usadas para la predicción)\n",
    "\n",
    "# Referenciamos columnas con indice de 0 a 111\n",
    "mi_comp_df = mi_df.iloc[:,112:124]\n",
    "mi_df = mi_df.iloc[:,0:112]\n",
    "\n",
    "mi_df = pd.concat([mi_df, mi_comp_df], axis=1, join='inner')\n",
    "# Removemos columnas 93, 94 , 95, 101, 102, 103, 104, 105\n",
    "mi_df.drop(mi_df.columns[[1-1, 93-1, 94-1 , 95-1, 101-1, 102-1, 103-1, 104-1, 105-1]],axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b894ba",
   "metadata": {},
   "source": [
    "### 1. Removemos columnas\n",
    "\n",
    "#### 1.1 Remover columnas que tienen un porcentaje de valores únicos superior al 70%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ea3653fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determinamos aquellas columnas (variables) que tengan un porcentaje de filas (registros) únicas por cada columna (variable) mayor al valor de 0.7\n",
    "threshold = 0.7\n",
    "\n",
    "unique_percentages = mi_df.nunique() / len(mi_df)\n",
    "\n",
    "criteria = unique_percentages > threshold\n",
    "\n",
    "columns_to_filter = unique_percentages[criteria].keys()\n",
    "\n",
    "#Eliminamos las columnas (variables) seleccionadas en el paso anterior. Al aplicar \"drop\" obtenemos un nuevo \"DataFrame\", pero con el parámetro\n",
    "#inplace igual a \"True\" podemos realizar dicha operación de eliminación y sobre-escribir el \"DataFrame\" del cual estamos eliminando con el\n",
    "#nuevo \"DataFrame\" obtenido. El parámetro axis permite seleccionar el eje respecto al cual aplicar la operación \"drop\". Los valores válidos\n",
    "#son [0 o \"index\"] y [1 o \"columns\"]\n",
    "mi_df.drop(columns_to_filter, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a58d723",
   "metadata": {},
   "source": [
    "### 2. Tratamiento de datos perdidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "90d50039",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from sklearn import preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "210cb3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### El dataset solo contiene variables numéricas y no contiene variables categóricas que tengan que ser codificadas\n",
    "\n",
    "# Agrupando columnas por tipo de datos\n",
    "tipos = mi_df.columns.to_series().groupby(mi_df.dtypes).groups\n",
    "\n",
    "# Armando lista de columnas categóricas\n",
    "cint = tipos[np.dtype('int64')]\n",
    "# Armando lista de columnas numéricas\n",
    "cfloat = tipos[np.dtype(\"float64\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "dd0b9781",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Para columnas que tengan > 20% de valores perdidos: Eliminar\n",
    "cols_mayor_a_20 = [col for col in mi_df.columns if ((mi_df[col].isnull().sum() / len(mi_df)*100) > 20.0)]\n",
    "\n",
    "mi_df.drop(\n",
    "    cols_mayor_a_20, \n",
    "    axis = 1, \n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "62c5bcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Para columnas que tengan entre 15% y 20% de valores perdidos: Imputar con modelos\n",
    "cols_entre_15_y_20 = [\n",
    "    col for col in mi_df.columns if \n",
    "        (((mi_df[col].isnull().sum() / len(mi_df)*100))>=15 and  \n",
    "        ((mi_df[col].isnull().sum() / len(mi_df)*100))<=20)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7c76501f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.pairplot(mi_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1774200a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['S_AD_ORIT', 'D_AD_ORIT', 'ALT_BLOOD', 'AST_BLOOD']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_entre_15_y_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "64d43ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Para columnas que tengan menos de 15% de valores perdidos: Imputar con Media, Moda y Mediana\n",
    "cols_menor_a_15 = [col for col in mi_df.columns if ((mi_df[col].isnull().sum() / len(mi_df)*100) < 15.0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07306a03",
   "metadata": {},
   "source": [
    "Notas de la libreria SimpleImputer para el parametro \"strategy\"\n",
    "\n",
    "- Si es \"mean\", reemplace los valores faltantes usando la media a lo largo de cada columna. Solo se puede usar con datos numéricos flotantes (float).\n",
    "\n",
    "- Si es \"median\", reemplace los valores faltantes usando la mediana a lo largo de cada columna. Solo se puede usar con datos numéricos enteros (int).\n",
    "\n",
    "- Si es \"most_frequent\", reemplace falta utilizando el valor más frecuente a lo largo de cada columna. Se puede usar con cadenas o datos numéricos que representan variables categóricas (str/int)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cee099c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_media = SimpleImputer(missing_values=np.nan, #etiqueta de valores nulos\n",
    "                    strategy='mean') #método o estrategia de imputación\n",
    "#imp_media es la función con los parámetros ya especificados de nuestra función\n",
    "\n",
    "imp_moda = SimpleImputer(missing_values=np.nan, #etiqueta de valores nulos\n",
    "                    strategy='most_frequent') #método o estrategia de imputación\n",
    "#imp_moda es la función con los parámetros ya especificados de nuestra función"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ab331eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_cols_int_lst = [col for col in cols_menor_a_15 if col in cint]\n",
    "\n",
    "mi_int_limpio_df = imp_moda.fit_transform(mi_df[missing_cols_int_lst])\n",
    "mi_int_limpio_df = pd.DataFrame(mi_int_limpio_df, columns=missing_cols_int_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f363e45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_cols_float_lst = [col for col in cols_menor_a_15 if col in cfloat]\n",
    "\n",
    "mi_float_limpio_df = imp_media.fit_transform(mi_df[missing_cols_float_lst])\n",
    "mi_float_limpio_df = pd.DataFrame(mi_float_limpio_df, columns=missing_cols_float_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f3720a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_df.drop(\n",
    "    missing_cols_int_lst+missing_cols_float_lst,\n",
    "    axis = 1, \n",
    "    inplace=True\n",
    ")\n",
    "mi_df = pd.concat([mi_df, mi_int_limpio_df], axis=1, join='inner')\n",
    "mi_df = pd.concat([mi_df, mi_float_limpio_df], axis=1, join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cc3e83c8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi_df[\"ZSN\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bd06e4e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((mi_df.isnull().sum() / len(mi_df)*100)>0.001).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ad528d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
