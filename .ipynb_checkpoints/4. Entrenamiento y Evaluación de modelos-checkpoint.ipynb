{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e11fadc2",
   "metadata": {},
   "source": [
    "# Pasos:\n",
    "\n",
    "1. Particionar datos de Entrenamiento (80%) y Pruebas(20%) \n",
    "2. Entrenar Modelos a evaluar:\n",
    "    - XGBoost\n",
    "    - SVM\n",
    "    - Ensamble Modelo (RandomForest o Arbol de decisión)\n",
    "    - Naive Bayes - Gausiano\n",
    "    - Redes Neuronales\n",
    "3. Evaluar los hiperparametros (RandomSearchCV)\n",
    "4. Entrenar modelos con mejores hiperparámetros encontrados en 3.\n",
    "5. Evaluar modelos con data de pruebas (Accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75965c7c",
   "metadata": {},
   "source": [
    "## 1) Lectura de datos - Distribución de conjunto de datos\n",
    "\n",
    "La distribución del conjunto de datos será de la siguiente manera: \n",
    "\n",
    "- Entrenamiento (80%)\n",
    "- Pruebas (20%)\n",
    "\n",
    "--- Ya fue aplicado en 2. Pre-procesamiento de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1815862a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import preprocessing, neighbors\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from pprint import pprint\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4653298",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lectura del dataset\n",
    "\n",
    "\n",
    "#Lectura del dataset\n",
    "\n",
    "X_TRAIN_DF = pd.read_csv('data/03_entrada_modelo/X_MI_entrenamiento_caracterizado.csv', header=0, sep=\",\")\n",
    "X_TEST_DF  = pd.read_csv('data/03_entrada_modelo/X_MI_pruebas_caracterizado.csv', header=0, sep=\",\")\n",
    "Y_TRAIN_DF = pd.read_csv('data/03_entrada_modelo/y_MI_entrenamiento_caracterizado.csv', header=0, sep=\",\")\n",
    "Y_TEST_DF  = pd.read_csv('data/03_entrada_modelo/y_MI_pruebas_caracterizado.csv', header=0, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05e111dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_objetivo_lst = [\n",
    "    'FIBR_PREDS','PREDS_TAH','JELUD_TAH','FIBR_JELUD',\n",
    "    'A_V_BLOK','OTEK_LANC','RAZRIV','DRESSLER','ZSN',\n",
    "    'REC_IM','P_IM_STEN'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a75200b",
   "metadata": {},
   "source": [
    "## 2) Entrenar Modelos a evaluar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dcc824c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Resultados con la métrica de exactitud (Accuracy) de cada uno de los modelos.\n",
    "resultados_modelo_metricas_df = pd.DataFrame(columns=['Variable Objetivo','Modelo','Accuracy Train','Accuracy Test', 'Especificidad', \"F1_score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18456e2",
   "metadata": {},
   "source": [
    "### 2.1) Random Forest\n",
    "\n",
    "Entrenamos el modelo de Random Forest de tipo clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4e4c576",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud del modelo inicial en entrenamiento: 1.0\n",
      "Exactitud del modelo inicial en entrenamiento (Out of Bag): 0.959731543624161\n",
      "Exactitud del modelo inicial en validación: 0.8970588235294118\n",
      "Los valores a probar en la búsqueda aleatoria son:\n",
      "{'max_depth': [10, 31, 52, 73, 94, 115, 136, 157, 178, 199, 220, None],\n",
      " 'max_features': ['auto', 10, 11, 12],\n",
      " 'min_samples_leaf': [1, 2, 4],\n",
      " 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n",
      "\n",
      "Si se probara todas las combinaciones se requeriría entrenar 1440 modelos\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Los hiperparámetros del mejor modelo son:\n",
      "{'max_depth': 52,\n",
      " 'max_features': 10,\n",
      " 'min_samples_leaf': 1,\n",
      " 'n_estimators': 1600}\n",
      "\n",
      "****************************************************************************************************\n",
      "FIBR_PREDS\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Exactitud luego de búsqueda aleatoria en entrenamiento: 1.0\n",
      "Exactitud luego de búsqueda aleatoria en entrenamiento (Out of Bag): 0.9635067114093959\n",
      "Exactitud luego de búsqueda aleatoria en validación: 0.8970588235294118\n",
      "..................................................\n",
      "Especificidad luego de búsqueda aleatoria en validación: 0.9837133550488599\n",
      "F1_score luego de búsqueda aleatoria en validación: 0.8676880347925269\n",
      "****************************************************************************************************\n",
      "Exactitud del modelo inicial en entrenamiento: 1.0\n",
      "Exactitud del modelo inicial en entrenamiento (Out of Bag): 0.9954233409610984\n",
      "Exactitud del modelo inicial en validación: 0.9852941176470589\n",
      "Los valores a probar en la búsqueda aleatoria son:\n",
      "{'max_depth': [10, 31, 52, 73, 94, 115, 136, 157, 178, 199, 220, None],\n",
      " 'max_features': ['auto', 10, 11, 12],\n",
      " 'min_samples_leaf': [1, 2, 4],\n",
      " 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n",
      "\n",
      "Si se probara todas las combinaciones se requeriría entrenar 1440 modelos\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Los hiperparámetros del mejor modelo son:\n",
      "{'max_depth': 115,\n",
      " 'max_features': 11,\n",
      " 'min_samples_leaf': 4,\n",
      " 'n_estimators': 1000}\n",
      "\n",
      "****************************************************************************************************\n",
      "PREDS_TAH\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Exactitud luego de búsqueda aleatoria en entrenamiento: 0.998093058733791\n",
      "Exactitud luego de búsqueda aleatoria en entrenamiento (Out of Bag): 0.9938977879481312\n",
      "Exactitud luego de búsqueda aleatoria en validación: 0.9852941176470589\n",
      "..................................................\n",
      "Especificidad luego de búsqueda aleatoria en validación: 1.0\n",
      "F1_score luego de búsqueda aleatoria en validación: 0.9779956427015251\n",
      "****************************************************************************************************\n",
      "Exactitud del modelo inicial en entrenamiento: 1.0\n",
      "Exactitud del modelo inicial en entrenamiento (Out of Bag): 0.9926442121564073\n",
      "Exactitud del modelo inicial en validación: 0.9794117647058823\n",
      "Los valores a probar en la búsqueda aleatoria son:\n",
      "{'max_depth': [10, 31, 52, 73, 94, 115, 136, 157, 178, 199, 220, None],\n",
      " 'max_features': ['auto', 10, 11, 12],\n",
      " 'min_samples_leaf': [1, 2, 4],\n",
      " 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n",
      "\n",
      "Si se probara todas las combinaciones se requeriría entrenar 1440 modelos\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Los hiperparámetros del mejor modelo son:\n",
      "{'max_depth': None,\n",
      " 'max_features': 11,\n",
      " 'min_samples_leaf': 1,\n",
      " 'n_estimators': 800}\n",
      "\n",
      "****************************************************************************************************\n",
      "JELUD_TAH\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Exactitud luego de búsqueda aleatoria en entrenamiento: 1.0\n",
      "Exactitud luego de búsqueda aleatoria en entrenamiento (Out of Bag): 0.9914827719705769\n",
      "Exactitud luego de búsqueda aleatoria en validación: 0.9794117647058823\n",
      "..................................................\n",
      "Especificidad luego de búsqueda aleatoria en validación: 1.0\n",
      "F1_score luego de búsqueda aleatoria en validación: 0.9692247181190454\n",
      "****************************************************************************************************\n",
      "Exactitud del modelo inicial en entrenamiento: 1.0\n",
      "Exactitud del modelo inicial en entrenamiento (Out of Bag): 0.9843014128728415\n",
      "Exactitud del modelo inicial en validación: 0.9470588235294117\n",
      "Los valores a probar en la búsqueda aleatoria son:\n",
      "{'max_depth': [10, 31, 52, 73, 94, 115, 136, 157, 178, 199, 220, None],\n",
      " 'max_features': ['auto', 10, 11, 12],\n",
      " 'min_samples_leaf': [1, 2, 4],\n",
      " 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n",
      "\n",
      "Si se probara todas las combinaciones se requeriría entrenar 1440 modelos\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\coliverac\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los hiperparámetros del mejor modelo son:\n",
      "{'max_depth': 220,\n",
      " 'max_features': 'auto',\n",
      " 'min_samples_leaf': 2,\n",
      " 'n_estimators': 1400}\n",
      "\n",
      "****************************************************************************************************\n",
      "FIBR_JELUD\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Exactitud luego de búsqueda aleatoria en entrenamiento: 0.9972527472527473\n",
      "Exactitud luego de búsqueda aleatoria en entrenamiento (Out of Bag): 0.9843014128728415\n",
      "Exactitud luego de búsqueda aleatoria en validación: 0.9441176470588235\n",
      "..................................................\n",
      "Especificidad luego de búsqueda aleatoria en validación: 0.9968944099378882\n",
      "F1_score luego de búsqueda aleatoria en validación: 0.919836255228264\n",
      "****************************************************************************************************\n",
      "Exactitud del modelo inicial en entrenamiento: 1.0\n",
      "Exactitud del modelo inicial en entrenamiento (Out of Bag): 0.9902419984387197\n",
      "Exactitud del modelo inicial en validación: 0.9705882352941176\n",
      "Los valores a probar en la búsqueda aleatoria son:\n",
      "{'max_depth': [10, 31, 52, 73, 94, 115, 136, 157, 178, 199, 220, None],\n",
      " 'max_features': ['auto', 10, 11, 12],\n",
      " 'min_samples_leaf': [1, 2, 4],\n",
      " 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n",
      "\n",
      "Si se probara todas las combinaciones se requeriría entrenar 1440 modelos\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Los hiperparámetros del mejor modelo son:\n",
      "{'max_depth': None,\n",
      " 'max_features': 11,\n",
      " 'min_samples_leaf': 1,\n",
      " 'n_estimators': 800}\n",
      "\n",
      "****************************************************************************************************\n",
      "A_V_BLOK\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Exactitud luego de búsqueda aleatoria en entrenamiento: 1.0\n",
      "Exactitud luego de búsqueda aleatoria en entrenamiento (Out of Bag): 0.9882903981264637\n",
      "Exactitud luego de búsqueda aleatoria en validación: 0.9705882352941176\n",
      "..................................................\n",
      "Especificidad luego de búsqueda aleatoria en validación: 1.0\n",
      "F1_score luego de búsqueda aleatoria en validación: 0.9585534812727485\n",
      "****************************************************************************************************\n",
      "Exactitud del modelo inicial en entrenamiento: 1.0\n",
      "Exactitud del modelo inicial en entrenamiento (Out of Bag): 0.95625\n",
      "Exactitud del modelo inicial en validación: 0.9058823529411765\n",
      "Los valores a probar en la búsqueda aleatoria son:\n",
      "{'max_depth': [10, 31, 52, 73, 94, 115, 136, 157, 178, 199, 220, None],\n",
      " 'max_features': ['auto', 10, 11, 12],\n",
      " 'min_samples_leaf': [1, 2, 4],\n",
      " 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n",
      "\n",
      "Si se probara todas las combinaciones se requeriría entrenar 1440 modelos\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Los hiperparámetros del mejor modelo son:\n",
      "{'max_depth': 52,\n",
      " 'max_features': 10,\n",
      " 'min_samples_leaf': 1,\n",
      " 'n_estimators': 1600}\n",
      "\n",
      "****************************************************************************************************\n",
      "OTEK_LANC\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Exactitud luego de búsqueda aleatoria en entrenamiento: 1.0\n",
      "Exactitud luego de búsqueda aleatoria en entrenamiento (Out of Bag): 0.9625\n",
      "Exactitud luego de búsqueda aleatoria en validación: 0.9117647058823529\n",
      "..................................................\n",
      "Especificidad luego de búsqueda aleatoria en validación: 0.9903225806451613\n",
      "F1_score luego de búsqueda aleatoria en validación: 0.8839970770917063\n",
      "****************************************************************************************************\n",
      "Exactitud del modelo inicial en entrenamiento: 1.0\n",
      "Exactitud del modelo inicial en entrenamiento (Out of Bag): 0.9906396255850234\n",
      "Exactitud del modelo inicial en validación: 0.9705882352941176\n",
      "Los valores a probar en la búsqueda aleatoria son:\n",
      "{'max_depth': [10, 31, 52, 73, 94, 115, 136, 157, 178, 199, 220, None],\n",
      " 'max_features': ['auto', 10, 11, 12],\n",
      " 'min_samples_leaf': [1, 2, 4],\n",
      " 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n",
      "\n",
      "Si se probara todas las combinaciones se requeriría entrenar 1440 modelos\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\coliverac\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los hiperparámetros del mejor modelo son:\n",
      "{'max_depth': 220,\n",
      " 'max_features': 'auto',\n",
      " 'min_samples_leaf': 2,\n",
      " 'n_estimators': 1400}\n",
      "\n",
      "****************************************************************************************************\n",
      "RAZRIV\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Exactitud luego de búsqueda aleatoria en entrenamiento: 0.998829953198128\n",
      "Exactitud luego de búsqueda aleatoria en entrenamiento (Out of Bag): 0.9894695787831513\n",
      "Exactitud luego de búsqueda aleatoria en validación: 0.9676470588235294\n",
      "..................................................\n",
      "Especificidad luego de búsqueda aleatoria en validación: 0.9939577039274925\n",
      "F1_score luego de búsqueda aleatoria en validación: 0.9575222017057944\n",
      "****************************************************************************************************\n",
      "Exactitud del modelo inicial en entrenamiento: 1.0\n",
      "Exactitud del modelo inicial en entrenamiento (Out of Bag): 0.9810725552050473\n",
      "Exactitud del modelo inicial en validación: 0.9529411764705882\n",
      "Los valores a probar en la búsqueda aleatoria son:\n",
      "{'max_depth': [10, 31, 52, 73, 94, 115, 136, 157, 178, 199, 220, None],\n",
      " 'max_features': ['auto', 10, 11, 12],\n",
      " 'min_samples_leaf': [1, 2, 4],\n",
      " 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n",
      "\n",
      "Si se probara todas las combinaciones se requeriría entrenar 1440 modelos\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Los hiperparámetros del mejor modelo son:\n",
      "{'max_depth': None,\n",
      " 'max_features': 11,\n",
      " 'min_samples_leaf': 1,\n",
      " 'n_estimators': 800}\n",
      "\n",
      "****************************************************************************************************\n",
      "DRESSLER\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Exactitud luego de búsqueda aleatoria en entrenamiento: 1.0\n",
      "Exactitud luego de búsqueda aleatoria en entrenamiento (Out of Bag): 0.9822555205047319\n",
      "Exactitud luego de búsqueda aleatoria en validación: 0.9470588235294117\n",
      "..................................................\n",
      "Especificidad luego de búsqueda aleatoria en validación: 0.9938271604938271\n",
      "F1_score luego de búsqueda aleatoria en validación: 0.9270303891949528\n",
      "****************************************************************************************************\n",
      "Exactitud del modelo inicial en entrenamiento: 1.0\n",
      "Exactitud del modelo inicial en entrenamiento (Out of Bag): 0.8884559181685339\n",
      "Exactitud del modelo inicial en validación: 0.7588235294117647\n",
      "Los valores a probar en la búsqueda aleatoria son:\n",
      "{'max_depth': [10, 31, 52, 73, 94, 115, 136, 157, 178, 199, 220, None],\n",
      " 'max_features': ['auto', 10, 11, 12],\n",
      " 'min_samples_leaf': [1, 2, 4],\n",
      " 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n",
      "\n",
      "Si se probara todas las combinaciones se requeriría entrenar 1440 modelos\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Los hiperparámetros del mejor modelo son:\n",
      "{'max_depth': 52,\n",
      " 'max_features': 10,\n",
      " 'min_samples_leaf': 1,\n",
      " 'n_estimators': 1600}\n",
      "\n",
      "****************************************************************************************************\n",
      "ZSN\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Exactitud luego de búsqueda aleatoria en entrenamiento: 1.0\n",
      "Exactitud luego de búsqueda aleatoria en entrenamiento (Out of Bag): 0.8938139308329274\n",
      "Exactitud luego de búsqueda aleatoria en validación: 0.7794117647058824\n",
      "..................................................\n",
      "Especificidad luego de búsqueda aleatoria en validación: 0.9641434262948207\n",
      "F1_score luego de búsqueda aleatoria en validación: 0.7387014800893672\n",
      "****************************************************************************************************\n",
      "Exactitud del modelo inicial en entrenamiento: 1.0\n",
      "Exactitud del modelo inicial en entrenamiento (Out of Bag): 0.9538977367979883\n",
      "Exactitud del modelo inicial en validación: 0.9264705882352942\n",
      "Los valores a probar en la búsqueda aleatoria son:\n",
      "{'max_depth': [10, 31, 52, 73, 94, 115, 136, 157, 178, 199, 220, None],\n",
      " 'max_features': ['auto', 10, 11, 12],\n",
      " 'min_samples_leaf': [1, 2, 4],\n",
      " 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n",
      "\n",
      "Si se probara todas las combinaciones se requeriría entrenar 1440 modelos\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Los hiperparámetros del mejor modelo son:\n",
      "{'max_depth': None,\n",
      " 'max_features': 11,\n",
      " 'min_samples_leaf': 1,\n",
      " 'n_estimators': 800}\n",
      "\n",
      "****************************************************************************************************\n",
      "REC_IM\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Exactitud luego de búsqueda aleatoria en entrenamiento: 1.0\n",
      "Exactitud luego de búsqueda aleatoria en entrenamiento (Out of Bag): 0.960184409052808\n",
      "Exactitud luego de búsqueda aleatoria en validación: 0.9205882352941176\n",
      "..................................................\n",
      "Especificidad luego de búsqueda aleatoria en validación: 0.990506329113924\n",
      "F1_score luego de búsqueda aleatoria en validación: 0.890982794342852\n",
      "****************************************************************************************************\n",
      "Exactitud del modelo inicial en entrenamiento: 1.0\n",
      "Exactitud del modelo inicial en entrenamiento (Out of Bag): 0.956953642384106\n",
      "Exactitud del modelo inicial en validación: 0.9205882352941176\n",
      "Los valores a probar en la búsqueda aleatoria son:\n",
      "{'max_depth': [10, 31, 52, 73, 94, 115, 136, 157, 178, 199, 220, None],\n",
      " 'max_features': ['auto', 10, 11, 12],\n",
      " 'min_samples_leaf': [1, 2, 4],\n",
      " 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n",
      "\n",
      "Si se probara todas las combinaciones se requeriría entrenar 1440 modelos\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Los hiperparámetros del mejor modelo son:\n",
      "{'max_depth': 52,\n",
      " 'max_features': 10,\n",
      " 'min_samples_leaf': 1,\n",
      " 'n_estimators': 1600}\n",
      "\n",
      "****************************************************************************************************\n",
      "P_IM_STEN\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Exactitud luego de búsqueda aleatoria en entrenamiento: 1.0\n",
      "Exactitud luego de búsqueda aleatoria en entrenamiento (Out of Bag): 0.9586092715231788\n",
      "Exactitud luego de búsqueda aleatoria en validación: 0.9088235294117647\n",
      "..................................................\n",
      "Especificidad luego de búsqueda aleatoria en validación: 0.9871794871794872\n",
      "F1_score luego de búsqueda aleatoria en validación: 0.8786705127463377\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "for var_objetivo in var_objetivo_lst:\n",
    "    \n",
    "    X_train = X_TRAIN_DF.loc[X_TRAIN_DF[\"var_objetivo\"]==var_objetivo].dropna(axis='columns')\n",
    "    y_train = Y_TRAIN_DF.loc[Y_TRAIN_DF[\"var_objetivo\"]==var_objetivo, var_objetivo]\n",
    "    X_test = X_TEST_DF.loc[X_TEST_DF[\"var_objetivo\"]==var_objetivo].dropna(axis='columns')\n",
    "    y_test = Y_TEST_DF.loc[Y_TEST_DF[\"var_objetivo\"]==var_objetivo, var_objetivo]\n",
    "    X_train.drop([\"var_objetivo\"], axis=1, inplace=True)\n",
    "    X_test.drop([\"var_objetivo\"], axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "    rf = RandomForestClassifier(oob_score = True)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    print('Exactitud del modelo inicial en entrenamiento:', rf.score(X_train, y_train))\n",
    "    print('Exactitud del modelo inicial en entrenamiento (Out of Bag):', rf.oob_score_)\n",
    "    print('Exactitud del modelo inicial en validación:', rf.score(X_test, y_test))\n",
    "\n",
    "    #### Búsqueda aleatoria de mejores hiperparámetros\n",
    "    # Definición de Grilla\n",
    "    n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "    max_features = ['auto', 10, 11, 12]  # 'auto' equivale a 'sqrt'; None equivale a todas\n",
    "    max_depth = [int(x) for x in np.linspace(10, 220, num = 11)] + [None]\n",
    "    min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "    random_grid = {'n_estimators': n_estimators,\n",
    "                   'max_features': max_features,\n",
    "                   'max_depth': max_depth,\n",
    "                   'min_samples_leaf': min_samples_leaf}\n",
    "\n",
    "    print('Los valores a probar en la búsqueda aleatoria son:')\n",
    "    pprint(random_grid)\n",
    "\n",
    "    print()\n",
    "    print('Si se probara todas las combinaciones se requeriría entrenar', \n",
    "          len(random_grid['n_estimators']) *\n",
    "          len(random_grid['max_features']) *\n",
    "          len(random_grid['max_depth']) *\n",
    "          len(random_grid['min_samples_leaf']),\n",
    "          'modelos'\n",
    "          )\n",
    "\n",
    "    rf = RandomForestClassifier(oob_score=True)\n",
    "    rf_random = RandomizedSearchCV(estimator = rf, \n",
    "                                   param_distributions = random_grid, \n",
    "                                   cv = 3,          # Validación cruzada 3-fold\n",
    "                                   verbose=2, \n",
    "                                   random_state=0, \n",
    "                                   n_jobs = -1      # Paralelizar en todos los cores disponibles\n",
    "                                   )\n",
    "    rf_random.fit(X_train, y_train)\n",
    "\n",
    "    ## Tomamos el mejor estimador encontrado en la búsqueda aleatoria por grilla.\n",
    "    rf_random_best = rf_random.best_estimator_\n",
    "\n",
    "    print('Los hiperparámetros del mejor modelo son:')\n",
    "    pprint(rf_random.best_params_)\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    y_pred = rf_random_best.predict(X_test)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    specificity = tn / (tn+fp)\n",
    "    f1_score_metric = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    resultados_modelo_metricas_df=resultados_modelo_metricas_df.append(\n",
    "        {\n",
    "            'Variable Objetivo' : var_objetivo,\n",
    "            'Modelo' : 'RandomForest' , \n",
    "            'Accuracy Train' : rf_random_best.score(X_train, y_train),\n",
    "            'Accuracy Test' : rf_random_best.score(X_test, y_test),\n",
    "            'Especificidad' : specificity,\n",
    "            'F1_score': f1_score_metric\n",
    "        },\n",
    "        ignore_index=True\n",
    "    )\n",
    "    \n",
    "    print('*'*100)\n",
    "    print(f'{var_objetivo}')\n",
    "    print('-'*100)\n",
    "    print('Exactitud luego de búsqueda aleatoria en entrenamiento:', rf_random_best.score(X_train, y_train))\n",
    "    print('Exactitud luego de búsqueda aleatoria en entrenamiento (Out of Bag):', rf_random_best.oob_score_)\n",
    "    print('Exactitud luego de búsqueda aleatoria en validación:', rf_random_best.score(X_test, y_test))\n",
    "    print('.'*50)\n",
    "    print('Especificidad luego de búsqueda aleatoria en validación:', specificity)\n",
    "    print('F1_score luego de búsqueda aleatoria en validación:', f1_score_metric)\n",
    "    print('*'*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d169fc0a",
   "metadata": {},
   "source": [
    "### 2.2) Ensamble - XGBoost\n",
    "\n",
    "Entrenamos el modelo de XGBoost de tipo clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aff1f527",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from pprint import pprint\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import time\n",
    "\n",
    "## XGBoostRegressor\n",
    "modelXGBC = XGBClassifier()\n",
    "\n",
    "\n",
    "## Creamos la Grilla\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 500, num = 5)]\n",
    "learning_rate = [0.01,0.1]\n",
    "max_depth = [i for i in range(2,8,2)]\n",
    "start = time.time()\n",
    "\n",
    "random_grid = {'max_depth': max_depth,\n",
    "               'n_estimators': n_estimators,\n",
    "               'colsample_bytree': [0.2, 0.6, 0.8],\n",
    "               'min_child_weight': [3, 5, 7],\n",
    "               'gamma': [0.3, 0.5, 0.7],\n",
    "               'subsample': [0.4, 0.6, 0.8, 1],\n",
    "               'learning_rate': learning_rate}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7267be37",
   "metadata": {},
   "source": [
    "#### Búsqueda aleatoria de mejores hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90514f94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\coliverac\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:39:55] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Los hiperparámetros del mejor modelo son:\n",
      "{'colsample_bytree': 0.6,\n",
      " 'gamma': 0.5,\n",
      " 'learning_rate': 0.1,\n",
      " 'max_depth': 6,\n",
      " 'min_child_weight': 5,\n",
      " 'n_estimators': 500,\n",
      " 'subsample': 0.8}\n",
      "\n",
      "****************************************************************************************************\n",
      "FIBR_PREDS\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Exactitud luego de búsqueda en grilla en entrenamiento: 99.958%\n",
      "Exactitud luego de búsqueda en grilla en validación: 87.941%\n",
      "..................................................\n",
      "Especificidad luego de búsqueda aleatoria en validación: 0.9674267100977199\n",
      "F1_score luego de búsqueda aleatoria en validación: 0.8532684884977615\n",
      "****************************************************************************************************\n",
      "17.817312955856323 segundos\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\coliverac\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:40:08] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Los hiperparámetros del mejor modelo son:\n",
      "{'colsample_bytree': 0.2,\n",
      " 'gamma': 0.7,\n",
      " 'learning_rate': 0.1,\n",
      " 'max_depth': 6,\n",
      " 'min_child_weight': 3,\n",
      " 'n_estimators': 400,\n",
      " 'subsample': 0.6}\n",
      "\n",
      "****************************************************************************************************\n",
      "PREDS_TAH\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Exactitud luego de búsqueda en grilla en entrenamiento: 99.733%\n",
      "Exactitud luego de búsqueda en grilla en validación: 98.529%\n",
      "..................................................\n",
      "Especificidad luego de búsqueda aleatoria en validación: 1.0\n",
      "F1_score luego de búsqueda aleatoria en validación: 0.9779956427015251\n",
      "****************************************************************************************************\n",
      "30.525303840637207 segundos\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\coliverac\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:40:24] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Los hiperparámetros del mejor modelo son:\n",
      "{'colsample_bytree': 0.6,\n",
      " 'gamma': 0.5,\n",
      " 'learning_rate': 0.1,\n",
      " 'max_depth': 6,\n",
      " 'min_child_weight': 5,\n",
      " 'n_estimators': 500,\n",
      " 'subsample': 0.8}\n",
      "\n",
      "****************************************************************************************************\n",
      "JELUD_TAH\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Exactitud luego de búsqueda en grilla en entrenamiento: 99.845%\n",
      "Exactitud luego de búsqueda en grilla en validación: 96.765%\n",
      "..................................................\n",
      "Especificidad luego de búsqueda aleatoria en validación: 0.987987987987988\n",
      "F1_score luego de búsqueda aleatoria en validación: 0.9633078343445001\n",
      "****************************************************************************************************\n",
      "46.51033282279968 segundos\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\coliverac\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:40:38] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Los hiperparámetros del mejor modelo son:\n",
      "{'colsample_bytree': 0.2,\n",
      " 'gamma': 0.7,\n",
      " 'learning_rate': 0.01,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 7,\n",
      " 'n_estimators': 400,\n",
      " 'subsample': 1}\n",
      "\n",
      "****************************************************************************************************\n",
      "FIBR_JELUD\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Exactitud luego de búsqueda en grilla en entrenamiento: 98.155%\n",
      "Exactitud luego de búsqueda en grilla en validación: 94.118%\n",
      "..................................................\n",
      "Especificidad luego de búsqueda aleatoria en validación: 0.9906832298136646\n",
      "F1_score luego de búsqueda aleatoria en validación: 0.9230856752759129\n",
      "****************************************************************************************************\n",
      "59.563440561294556 segundos\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\coliverac\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:40:50] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Los hiperparámetros del mejor modelo son:\n",
      "{'colsample_bytree': 0.6,\n",
      " 'gamma': 0.5,\n",
      " 'learning_rate': 0.1,\n",
      " 'max_depth': 6,\n",
      " 'min_child_weight': 5,\n",
      " 'n_estimators': 500,\n",
      " 'subsample': 0.8}\n",
      "\n",
      "****************************************************************************************************\n",
      "A_V_BLOK\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Exactitud luego de búsqueda en grilla en entrenamiento: 99.883%\n",
      "Exactitud luego de búsqueda en grilla en validación: 97.059%\n",
      "..................................................\n",
      "Especificidad luego de búsqueda aleatoria en validación: 1.0\n",
      "F1_score luego de búsqueda aleatoria en validación: 0.9585534812727485\n",
      "****************************************************************************************************\n",
      "72.8748927116394 segundos\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\coliverac\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:41:06] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Los hiperparámetros del mejor modelo son:\n",
      "{'colsample_bytree': 0.2,\n",
      " 'gamma': 0.7,\n",
      " 'learning_rate': 0.1,\n",
      " 'max_depth': 6,\n",
      " 'min_child_weight': 3,\n",
      " 'n_estimators': 400,\n",
      " 'subsample': 0.6}\n",
      "\n",
      "****************************************************************************************************\n",
      "OTEK_LANC\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Exactitud luego de búsqueda en grilla en entrenamiento: 99.167%\n",
      "Exactitud luego de búsqueda en grilla en validación: 88.824%\n",
      "..................................................\n",
      "Especificidad luego de búsqueda aleatoria en validación: 0.9741935483870968\n",
      "F1_score luego de búsqueda aleatoria en validación: 0.8577973245372914\n",
      "****************************************************************************************************\n",
      "88.03813028335571 segundos\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\coliverac\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:41:18] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Los hiperparámetros del mejor modelo son:\n",
      "{'colsample_bytree': 0.6,\n",
      " 'gamma': 0.5,\n",
      " 'learning_rate': 0.1,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 7,\n",
      " 'n_estimators': 300,\n",
      " 'subsample': 1}\n",
      "\n",
      "****************************************************************************************************\n",
      "RAZRIV\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Exactitud luego de búsqueda en grilla en entrenamiento: 99.649%\n",
      "Exactitud luego de búsqueda en grilla en validación: 96.471%\n",
      "..................................................\n",
      "Especificidad luego de búsqueda aleatoria en validación: 0.9909365558912386\n",
      "F1_score luego de búsqueda aleatoria en validación: 0.9560408594575552\n",
      "****************************************************************************************************\n",
      "99.9295346736908 segundos\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\coliverac\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:41:30] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Los hiperparámetros del mejor modelo son:\n",
      "{'colsample_bytree': 0.2,\n",
      " 'gamma': 0.7,\n",
      " 'learning_rate': 0.1,\n",
      " 'max_depth': 6,\n",
      " 'min_child_weight': 3,\n",
      " 'n_estimators': 400,\n",
      " 'subsample': 0.6}\n",
      "\n",
      "****************************************************************************************************\n",
      "DRESSLER\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Exactitud luego de búsqueda en grilla en entrenamiento: 99.172%\n",
      "Exactitud luego de búsqueda en grilla en validación: 95.294%\n",
      "..................................................\n",
      "Especificidad luego de búsqueda aleatoria en validación: 1.0\n",
      "F1_score luego de búsqueda aleatoria en validación: 0.9299787384833451\n",
      "****************************************************************************************************\n",
      "112.56190943717957 segundos\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\coliverac\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:41:44] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Los hiperparámetros del mejor modelo son:\n",
      "{'colsample_bytree': 0.2,\n",
      " 'gamma': 0.7,\n",
      " 'learning_rate': 0.01,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 7,\n",
      " 'n_estimators': 400,\n",
      " 'subsample': 1}\n",
      "\n",
      "****************************************************************************************************\n",
      "ZSN\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Exactitud luego de búsqueda en grilla en entrenamiento: 88.358%\n",
      "Exactitud luego de búsqueda en grilla en validación: 78.235%\n",
      "..................................................\n",
      "Especificidad luego de búsqueda aleatoria en validación: 0.9840637450199203\n",
      "F1_score luego de búsqueda aleatoria en validación: 0.7308697774884603\n",
      "****************************************************************************************************\n",
      "126.22473549842834 segundos\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\coliverac\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:41:59] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Los hiperparámetros del mejor modelo son:\n",
      "{'colsample_bytree': 0.2,\n",
      " 'gamma': 0.7,\n",
      " 'learning_rate': 0.1,\n",
      " 'max_depth': 6,\n",
      " 'min_child_weight': 3,\n",
      " 'n_estimators': 400,\n",
      " 'subsample': 0.6}\n",
      "\n",
      "****************************************************************************************************\n",
      "REC_IM\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Exactitud luego de búsqueda en grilla en entrenamiento: 99.246%\n",
      "Exactitud luego de búsqueda en grilla en validación: 91.176%\n",
      "..................................................\n",
      "Especificidad luego de búsqueda aleatoria en validación: 0.9778481012658228\n",
      "F1_score luego de búsqueda aleatoria en validación: 0.8907952069716778\n",
      "****************************************************************************************************\n",
      "141.66057133674622 segundos\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\coliverac\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:42:14] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Los hiperparámetros del mejor modelo son:\n",
      "{'colsample_bytree': 0.6,\n",
      " 'gamma': 0.5,\n",
      " 'learning_rate': 0.1,\n",
      " 'max_depth': 4,\n",
      " 'min_child_weight': 7,\n",
      " 'n_estimators': 300,\n",
      " 'subsample': 1}\n",
      "\n",
      "****************************************************************************************************\n",
      "P_IM_STEN\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Exactitud luego de búsqueda en grilla en entrenamiento: 98.717%\n",
      "Exactitud luego de búsqueda en grilla en validación: 90.588%\n",
      "..................................................\n",
      "Especificidad luego de búsqueda aleatoria en validación: 0.9839743589743589\n",
      "F1_score luego de búsqueda aleatoria en validación: 0.8770351484246947\n",
      "****************************************************************************************************\n",
      "155.9790620803833 segundos\n"
     ]
    }
   ],
   "source": [
    "for var_objetivo in var_objetivo_lst:    \n",
    "    \n",
    "    X_train = X_TRAIN_DF.loc[X_TRAIN_DF[\"var_objetivo\"]==var_objetivo].dropna(axis='columns')\n",
    "    y_train = Y_TRAIN_DF.loc[Y_TRAIN_DF[\"var_objetivo\"]==var_objetivo, var_objetivo]\n",
    "    X_test = X_TEST_DF.loc[X_TEST_DF[\"var_objetivo\"]==var_objetivo].dropna(axis='columns')\n",
    "    y_test = Y_TEST_DF.loc[Y_TEST_DF[\"var_objetivo\"]==var_objetivo, var_objetivo]\n",
    "    X_train.drop([\"var_objetivo\"], axis=1, inplace=True)\n",
    "    X_test.drop([\"var_objetivo\"], axis=1, inplace=True)\n",
    "    \n",
    "    xgb_random = RandomizedSearchCV(estimator = modelXGBC, \n",
    "                                   param_distributions = random_grid, \n",
    "                                   cv = 3,          # Validación cruzada 3-fold\n",
    "                                   verbose=2, \n",
    "                                   random_state=0, \n",
    "                                   n_jobs = -1      # Paralelizar en todos los cores disponibles\n",
    "                                   )\n",
    "    xgb_random.fit(X_train, y_train)\n",
    "    ## Tomamos el mejor estimador encontrado en la búsqueda aleatoria por grilla.\n",
    "    xgb_best_model = xgb_random.best_estimator_\n",
    "\n",
    "    print('Los hiperparámetros del mejor modelo son:')\n",
    "    pprint(xgb_random.best_params_)\n",
    "    print()\n",
    "\n",
    "\n",
    "    y_pred = xgb_best_model.predict(X_test)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    specificity = tn / (tn+fp)\n",
    "    f1_score_metric = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    score_XGBR_train = xgb_best_model.score(X_train, y_train)\n",
    "    score_XGBR_val = xgb_best_model.score(X_test, y_test)\n",
    "    \n",
    "    resultados_modelo_metricas_df=resultados_modelo_metricas_df.append(\n",
    "        {\n",
    "            'Variable Objetivo' : var_objetivo,\n",
    "            'Modelo' : 'XGBoost' , \n",
    "            'Accuracy Train' : score_XGBR_train,\n",
    "            'Accuracy Test' : score_XGBR_val,\n",
    "            'Especificidad' : specificity,\n",
    "            'F1_score': f1_score_metric\n",
    "        },\n",
    "        ignore_index=True\n",
    "    )\n",
    "\n",
    "    print('*'*100)\n",
    "    print(f'{var_objetivo}')\n",
    "    print('-'*100)\n",
    "    print(f\"Exactitud luego de búsqueda en grilla en entrenamiento: {score_XGBR_train*100:.3f}%\")\n",
    "    print(f\"Exactitud luego de búsqueda en grilla en validación: {score_XGBR_val*100:.3f}%\")\n",
    "    print('.'*50)\n",
    "    print('Especificidad luego de búsqueda aleatoria en validación:', specificity)\n",
    "    print('F1_score luego de búsqueda aleatoria en validación:', f1_score_metric)\n",
    "    print('*'*100)\n",
    "    end = time.time()\n",
    "    print(f\"{end-start} segundos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6760d65",
   "metadata": {},
   "source": [
    "### 2.3) SVM\n",
    "\n",
    "Entrenamos el modelo de SVM de tipo clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2f15711",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "modelSVM = svm.SVC()\n",
    "# Entrenamiento del modelo base - SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b00f9e",
   "metadata": {},
   "source": [
    "#### Búsqueda aleatoria de mejores hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "322c6074",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 12 folds for each of 10 candidates, totalling 120 fits\n",
      "Los hiperparámetros del mejor modelo son:\n",
      "{'C': 10000.0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "\n",
      "****************************************************************************************************\n",
      "FIBR_PREDS\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Exactitud luego de búsqueda en grilla en entrenamiento: 1.000\n",
      "Exactitud luego de búsqueda en grilla en validación: 0.812\n",
      "..................................................\n",
      "Especificidad luego de búsqueda aleatoria en validación: 0.8827361563517915\n",
      "F1_score luego de búsqueda aleatoria en validación: 0.8206971094565735\n",
      "****************************************************************************************************\n",
      "185.08181929588318\n",
      "Fitting 12 folds for each of 10 candidates, totalling 120 fits\n",
      "Los hiperparámetros del mejor modelo son:\n",
      "{'C': 10000.0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "\n",
      "****************************************************************************************************\n",
      "PREDS_TAH\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Exactitud luego de búsqueda en grilla en entrenamiento: 1.000\n",
      "Exactitud luego de búsqueda en grilla en validación: 0.974\n",
      "..................................................\n",
      "Especificidad luego de búsqueda aleatoria en validación: 0.9850746268656716\n",
      "F1_score luego de búsqueda aleatoria en validación: 0.974712836622623\n",
      "****************************************************************************************************\n",
      "219.5832793712616\n",
      "Fitting 12 folds for each of 10 candidates, totalling 120 fits\n",
      "Los hiperparámetros del mejor modelo son:\n",
      "{'C': 10000.0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "\n",
      "****************************************************************************************************\n",
      "JELUD_TAH\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Exactitud luego de búsqueda en grilla en entrenamiento: 1.000\n",
      "Exactitud luego de búsqueda en grilla en validación: 0.956\n",
      "..................................................\n",
      "Especificidad luego de búsqueda aleatoria en validación: 0.975975975975976\n",
      "F1_score luego de búsqueda aleatoria en validación: 0.9573197700132684\n",
      "****************************************************************************************************\n",
      "245.77299904823303\n",
      "Fitting 12 folds for each of 10 candidates, totalling 120 fits\n",
      "Los hiperparámetros del mejor modelo son:\n",
      "{'C': 10000.0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "\n",
      "****************************************************************************************************\n",
      "FIBR_JELUD\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Exactitud luego de búsqueda en grilla en entrenamiento: 1.000\n",
      "Exactitud luego de búsqueda en grilla en validación: 0.921\n",
      "..................................................\n",
      "Especificidad luego de búsqueda aleatoria en validación: 0.9596273291925466\n",
      "F1_score luego de búsqueda aleatoria en validación: 0.919515341020129\n",
      "****************************************************************************************************\n",
      "278.571897983551\n",
      "Fitting 12 folds for each of 10 candidates, totalling 120 fits\n",
      "Los hiperparámetros del mejor modelo son:\n",
      "{'C': 10000.0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "\n",
      "****************************************************************************************************\n",
      "A_V_BLOK\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Exactitud luego de búsqueda en grilla en entrenamiento: 1.000\n",
      "Exactitud luego de búsqueda en grilla en validación: 0.929\n",
      "..................................................\n",
      "Especificidad luego de búsqueda aleatoria en validación: 0.9574468085106383\n",
      "F1_score luego de búsqueda aleatoria en validación: 0.934625762796297\n",
      "****************************************************************************************************\n",
      "304.22904682159424\n",
      "Fitting 12 folds for each of 10 candidates, totalling 120 fits\n",
      "Los hiperparámetros del mejor modelo son:\n",
      "{'C': 10000.0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "\n",
      "****************************************************************************************************\n",
      "OTEK_LANC\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Exactitud luego de búsqueda en grilla en entrenamiento: 0.999\n",
      "Exactitud luego de búsqueda en grilla en validación: 0.865\n",
      "..................................................\n",
      "Especificidad luego de búsqueda aleatoria en validación: 0.932258064516129\n",
      "F1_score luego de búsqueda aleatoria en validación: 0.8603075845722904\n",
      "****************************************************************************************************\n",
      "334.0531795024872\n",
      "Fitting 12 folds for each of 10 candidates, totalling 120 fits\n",
      "Los hiperparámetros del mejor modelo son:\n",
      "{'C': 10000.0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "\n",
      "****************************************************************************************************\n",
      "RAZRIV\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Exactitud luego de búsqueda en grilla en entrenamiento: 1.000\n",
      "Exactitud luego de búsqueda en grilla en validación: 0.953\n",
      "..................................................\n",
      "Especificidad luego de búsqueda aleatoria en validación: 0.9788519637462235\n",
      "F1_score luego de búsqueda aleatoria en validación: 0.9500708717221827\n",
      "****************************************************************************************************\n",
      "361.3860590457916\n",
      "Fitting 12 folds for each of 10 candidates, totalling 120 fits\n",
      "Los hiperparámetros del mejor modelo son:\n",
      "{'C': 10000.0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "\n",
      "****************************************************************************************************\n",
      "DRESSLER\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Exactitud luego de búsqueda en grilla en entrenamiento: 0.999\n",
      "Exactitud luego de búsqueda en grilla en validación: 0.882\n",
      "..................................................\n",
      "Especificidad luego de búsqueda aleatoria en validación: 0.9259259259259259\n",
      "F1_score luego de búsqueda aleatoria en validación: 0.8933823529411766\n",
      "****************************************************************************************************\n",
      "394.3162784576416\n",
      "Fitting 12 folds for each of 10 candidates, totalling 120 fits\n",
      "Los hiperparámetros del mejor modelo son:\n",
      "{'C': 10000.0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "\n",
      "****************************************************************************************************\n",
      "ZSN\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Exactitud luego de búsqueda en grilla en entrenamiento: 0.993\n",
      "Exactitud luego de búsqueda en grilla en validación: 0.653\n",
      "..................................................\n",
      "Especificidad luego de búsqueda aleatoria en validación: 0.7888446215139442\n",
      "F1_score luego de búsqueda aleatoria en validación: 0.6444481519577968\n",
      "****************************************************************************************************\n",
      "421.7094614505768\n",
      "Fitting 12 folds for each of 10 candidates, totalling 120 fits\n",
      "Los hiperparámetros del mejor modelo son:\n",
      "{'C': 10000.0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "\n",
      "****************************************************************************************************\n",
      "REC_IM\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Exactitud luego de búsqueda en grilla en entrenamiento: 0.999\n",
      "Exactitud luego de búsqueda en grilla en validación: 0.812\n",
      "..................................................\n",
      "Especificidad luego de búsqueda aleatoria en validación: 0.8639240506329114\n",
      "F1_score luego de búsqueda aleatoria en validación: 0.8379501308720211\n",
      "****************************************************************************************************\n",
      "455.58066058158875\n",
      "Fitting 12 folds for each of 10 candidates, totalling 120 fits\n",
      "Los hiperparámetros del mejor modelo son:\n",
      "{'C': 10000.0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "\n",
      "****************************************************************************************************\n",
      "P_IM_STEN\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Exactitud luego de búsqueda en grilla en entrenamiento: 0.997\n",
      "Exactitud luego de búsqueda en grilla en validación: 0.835\n",
      "..................................................\n",
      "Especificidad luego de búsqueda aleatoria en validación: 0.9006410256410257\n",
      "F1_score luego de búsqueda aleatoria en validación: 0.8424642139975314\n",
      "****************************************************************************************************\n",
      "493.9770841598511\n"
     ]
    }
   ],
   "source": [
    "for var_objetivo in var_objetivo_lst:\n",
    "    # Lectura\n",
    "    X_train = X_TRAIN_DF.loc[X_TRAIN_DF[\"var_objetivo\"]==var_objetivo].dropna(axis='columns')\n",
    "    y_train = Y_TRAIN_DF.loc[Y_TRAIN_DF[\"var_objetivo\"]==var_objetivo, var_objetivo]\n",
    "    X_test = X_TEST_DF.loc[X_TEST_DF[\"var_objetivo\"]==var_objetivo].dropna(axis='columns')\n",
    "    y_test = Y_TEST_DF.loc[Y_TEST_DF[\"var_objetivo\"]==var_objetivo, var_objetivo]\n",
    "    X_train.drop([\"var_objetivo\"], axis=1, inplace=True)\n",
    "    X_test.drop([\"var_objetivo\"], axis=1, inplace=True)\n",
    "    \n",
    "    # Definición de grilla\n",
    "    random_grid = {'kernel': ['rbf'],\n",
    "                   'C': np.logspace(-4,4,9), # [0.0001, 0.001, ..., 10000]\n",
    "                   'gamma': np.logspace(-4,4,9)  # [0.0001, 0.001, ..., 10000]\n",
    "                  }\n",
    "\n",
    "    modelSVM_random = RandomizedSearchCV(estimator = modelSVM, \n",
    "                                   param_distributions = random_grid, \n",
    "                                   cv = 12,          # Validación cruzada 3-fold\n",
    "                                   verbose=2, \n",
    "                                   random_state=0, \n",
    "                                   n_jobs = -1      # Paralelizar en todos los cores disponibles\n",
    "                                   )\n",
    "    modelSVM_random.fit(X_train, y_train)\n",
    "\n",
    "    ## Tomamos el mejor estimador encontrado en la búsqueda aleatoria por grilla.\n",
    "    modelSVM_best_model = modelSVM_random.best_estimator_\n",
    "\n",
    "    print('Los hiperparámetros del mejor modelo son:')\n",
    "    pprint(modelSVM_random.best_params_)\n",
    "    print()\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    y_pred = modelSVM_best_model.predict(X_test)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    specificity = tn / (tn+fp)\n",
    "    f1_score_metric = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    score_SVM_train = modelSVM_best_model.score(X_train, y_train)\n",
    "    score_SVM_test = modelSVM_best_model.score(X_test, y_test)\n",
    "    \n",
    "    resultados_modelo_metricas_df=resultados_modelo_metricas_df.append(\n",
    "        {\n",
    "            'Variable Objetivo' : var_objetivo,\n",
    "            'Modelo' : 'SVM' , \n",
    "            'Accuracy Train' : score_SVM_train,\n",
    "            'Accuracy Test' : score_SVM_test,\n",
    "            'Especificidad' : specificity,\n",
    "            'F1_score': f1_score_metric\n",
    "        },\n",
    "        ignore_index=True\n",
    "    )\n",
    "    \n",
    "    \n",
    "    print('*'*100)\n",
    "    print(f'{var_objetivo}')\n",
    "    print('-'*100)\n",
    "    print(f\"Exactitud luego de búsqueda aleatoria en grilla en entrenamiento: {score_SVM_train:.3f}\")\n",
    "    print(f\"Exactitud luego de búsqueda aleatoria en grilla en validación: {score_SVM_test:.3f}\")\n",
    "    print('.'*50)\n",
    "    print('Especificidad luego de búsqueda aleatoria en validación:', specificity)\n",
    "    print('F1_score luego de búsqueda aleatoria en validación:', f1_score_metric)\n",
    "    print('*'*100)\n",
    "    end = time.time()\n",
    "    print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1170c46",
   "metadata": {},
   "source": [
    "### 2.4. Naive Bayes\n",
    "\n",
    "Entrenamos el modelo de Naive Bayes (Gausiano) de tipo clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7ba7ee0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad8b479d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los valores a probar en la búsqueda aleatoria son:\n",
      "{'var_smoothing': array([1.00000000e+00, 8.11130831e-01, 6.57933225e-01, 5.33669923e-01,\n",
      "       4.32876128e-01, 3.51119173e-01, 2.84803587e-01, 2.31012970e-01,\n",
      "       1.87381742e-01, 1.51991108e-01, 1.23284674e-01, 1.00000000e-01,\n",
      "       8.11130831e-02, 6.57933225e-02, 5.33669923e-02, 4.32876128e-02,\n",
      "       3.51119173e-02, 2.84803587e-02, 2.31012970e-02, 1.87381742e-02,\n",
      "       1.51991108e-02, 1.23284674e-02, 1.00000000e-02, 8.11130831e-03,\n",
      "       6.57933225e-03, 5.33669923e-03, 4.32876128e-03, 3.51119173e-03,\n",
      "       2.84803587e-03, 2.31012970e-03, 1.87381742e-03, 1.51991108e-03,\n",
      "       1.23284674e-03, 1.00000000e-03, 8.11130831e-04, 6.57933225e-04,\n",
      "       5.33669923e-04, 4.32876128e-04, 3.51119173e-04, 2.84803587e-04,\n",
      "       2.31012970e-04, 1.87381742e-04, 1.51991108e-04, 1.23284674e-04,\n",
      "       1.00000000e-04, 8.11130831e-05, 6.57933225e-05, 5.33669923e-05,\n",
      "       4.32876128e-05, 3.51119173e-05, 2.84803587e-05, 2.31012970e-05,\n",
      "       1.87381742e-05, 1.51991108e-05, 1.23284674e-05, 1.00000000e-05,\n",
      "       8.11130831e-06, 6.57933225e-06, 5.33669923e-06, 4.32876128e-06,\n",
      "       3.51119173e-06, 2.84803587e-06, 2.31012970e-06, 1.87381742e-06,\n",
      "       1.51991108e-06, 1.23284674e-06, 1.00000000e-06, 8.11130831e-07,\n",
      "       6.57933225e-07, 5.33669923e-07, 4.32876128e-07, 3.51119173e-07,\n",
      "       2.84803587e-07, 2.31012970e-07, 1.87381742e-07, 1.51991108e-07,\n",
      "       1.23284674e-07, 1.00000000e-07, 8.11130831e-08, 6.57933225e-08,\n",
      "       5.33669923e-08, 4.32876128e-08, 3.51119173e-08, 2.84803587e-08,\n",
      "       2.31012970e-08, 1.87381742e-08, 1.51991108e-08, 1.23284674e-08,\n",
      "       1.00000000e-08, 8.11130831e-09, 6.57933225e-09, 5.33669923e-09,\n",
      "       4.32876128e-09, 3.51119173e-09, 2.84803587e-09, 2.31012970e-09,\n",
      "       1.87381742e-09, 1.51991108e-09, 1.23284674e-09, 1.00000000e-09])}\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Los hiperparámetros del mejor modelo son:\n",
      "{'var_smoothing': 0.03511191734215131}\n",
      "\n",
      "****************************************************************************************************\n",
      "FIBR_PREDS\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Exactitud luego de búsqueda en grilla en entrenamiento: 0.718\n",
      "Exactitud luego de búsqueda en grilla en validación: 0.606\n",
      "..................................................\n",
      "Especificidad luego de búsqueda aleatoria en validación: 0.6156351791530945\n",
      "F1_score luego de búsqueda aleatoria en validación: 0.6862673975840335\n",
      "****************************************************************************************************\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Los hiperparámetros del mejor modelo son:\n",
      "{'var_smoothing': 0.03511191734215131}\n",
      "\n",
      "****************************************************************************************************\n",
      "PREDS_TAH\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Exactitud luego de búsqueda en grilla en entrenamiento: 0.696\n",
      "Exactitud luego de búsqueda en grilla en validación: 0.429\n",
      "..................................................\n",
      "Especificidad luego de búsqueda aleatoria en validación: 0.4298507462686567\n",
      "F1_score luego de búsqueda aleatoria en validación: 0.5890205447198369\n",
      "****************************************************************************************************\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Los hiperparámetros del mejor modelo son:\n",
      "{'var_smoothing': 0.03511191734215131}\n",
      "\n",
      "****************************************************************************************************\n",
      "JELUD_TAH\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Exactitud luego de búsqueda en grilla en entrenamiento: 0.821\n",
      "Exactitud luego de búsqueda en grilla en validación: 0.771\n",
      "..................................................\n",
      "Especificidad luego de búsqueda aleatoria en validación: 0.7837837837837838\n",
      "F1_score luego de búsqueda aleatoria en validación: 0.8526029411764705\n",
      "****************************************************************************************************\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Los hiperparámetros del mejor modelo son:\n",
      "{'var_smoothing': 0.03511191734215131}\n",
      "\n",
      "****************************************************************************************************\n",
      "FIBR_JELUD\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Exactitud luego de búsqueda en grilla en entrenamiento: 0.785\n",
      "Exactitud luego de búsqueda en grilla en validación: 0.718\n",
      "..................................................\n",
      "Especificidad luego de búsqueda aleatoria en validación: 0.7236024844720497\n",
      "F1_score luego de búsqueda aleatoria en validación: 0.7951540396603783\n",
      "****************************************************************************************************\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Los hiperparámetros del mejor modelo son:\n",
      "{'var_smoothing': 0.03511191734215131}\n",
      "\n",
      "****************************************************************************************************\n",
      "A_V_BLOK\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Exactitud luego de búsqueda en grilla en entrenamiento: 0.728\n",
      "Exactitud luego de búsqueda en grilla en validación: 0.544\n",
      "..................................................\n",
      "Especificidad luego de búsqueda aleatoria en validación: 0.5379939209726444\n",
      "F1_score luego de búsqueda aleatoria en validación: 0.6760076449840268\n",
      "****************************************************************************************************\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Los hiperparámetros del mejor modelo son:\n",
      "{'var_smoothing': 0.03511191734215131}\n",
      "\n",
      "****************************************************************************************************\n",
      "OTEK_LANC\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Exactitud luego de búsqueda en grilla en entrenamiento: 0.665\n",
      "Exactitud luego de búsqueda en grilla en validación: 0.515\n",
      "..................................................\n",
      "Especificidad luego de búsqueda aleatoria en validación: 0.4967741935483871\n",
      "F1_score luego de búsqueda aleatoria en validación: 0.61161006364123\n",
      "****************************************************************************************************\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Los hiperparámetros del mejor modelo son:\n",
      "{'var_smoothing': 0.004328761281083057}\n",
      "\n",
      "****************************************************************************************************\n",
      "RAZRIV\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Exactitud luego de búsqueda en grilla en entrenamiento: 0.821\n",
      "Exactitud luego de búsqueda en grilla en validación: 0.750\n",
      "..................................................\n",
      "Especificidad luego de búsqueda aleatoria en validación: 0.7643504531722054\n",
      "F1_score luego de búsqueda aleatoria en validación: 0.834702180649822\n",
      "****************************************************************************************************\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Los hiperparámetros del mejor modelo son:\n",
      "{'var_smoothing': 0.03511191734215131}\n",
      "\n",
      "****************************************************************************************************\n",
      "DRESSLER\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Exactitud luego de búsqueda en grilla en entrenamiento: 0.720\n",
      "Exactitud luego de búsqueda en grilla en validación: 0.550\n",
      "..................................................\n",
      "Especificidad luego de búsqueda aleatoria en validación: 0.5493827160493827\n",
      "F1_score luego de búsqueda aleatoria en validación: 0.6714507289835591\n",
      "****************************************************************************************************\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Los hiperparámetros del mejor modelo son:\n",
      "{'var_smoothing': 0.004328761281083057}\n",
      "\n",
      "****************************************************************************************************\n",
      "ZSN\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Exactitud luego de búsqueda en grilla en entrenamiento: 0.617\n",
      "Exactitud luego de búsqueda en grilla en validación: 0.418\n",
      "..................................................\n",
      "Especificidad luego de búsqueda aleatoria en validación: 0.3665338645418327\n",
      "F1_score luego de búsqueda aleatoria en validación: 0.44343028050673516\n",
      "****************************************************************************************************\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los hiperparámetros del mejor modelo son:\n",
      "{'var_smoothing': 0.03511191734215131}\n",
      "\n",
      "****************************************************************************************************\n",
      "REC_IM\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Exactitud luego de búsqueda en grilla en entrenamiento: 0.658\n",
      "Exactitud luego de búsqueda en grilla en validación: 0.421\n",
      "..................................................\n",
      "Especificidad luego de búsqueda aleatoria en validación: 0.3987341772151899\n",
      "F1_score luego de búsqueda aleatoria en validación: 0.5320193758815532\n",
      "****************************************************************************************************\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Los hiperparámetros del mejor modelo son:\n",
      "{'var_smoothing': 0.03511191734215131}\n",
      "\n",
      "****************************************************************************************************\n",
      "P_IM_STEN\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Exactitud luego de búsqueda en grilla en entrenamiento: 0.702\n",
      "Exactitud luego de búsqueda en grilla en validación: 0.485\n",
      "..................................................\n",
      "Especificidad luego de búsqueda aleatoria en validación: 0.46474358974358976\n",
      "F1_score luego de búsqueda aleatoria en validación: 0.5876174926084464\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "modelNB = GaussianNB()\n",
    "#modelNB.fit(X_train, y_train)\n",
    "\n",
    "params_NB = {'var_smoothing': np.logspace(0,-9, num=100)}\n",
    "\n",
    "print('Los valores a probar en la búsqueda aleatoria son:')\n",
    "pprint(params_NB)\n",
    "\n",
    "\n",
    "for var_objetivo in var_objetivo_lst:\n",
    "    # Lectura\n",
    "    X_train = X_TRAIN_DF.loc[X_TRAIN_DF[\"var_objetivo\"]==var_objetivo].dropna(axis='columns')\n",
    "    y_train = Y_TRAIN_DF.loc[Y_TRAIN_DF[\"var_objetivo\"]==var_objetivo, var_objetivo]\n",
    "    X_test = X_TEST_DF.loc[X_TEST_DF[\"var_objetivo\"]==var_objetivo].dropna(axis='columns')\n",
    "    y_test = Y_TEST_DF.loc[Y_TEST_DF[\"var_objetivo\"]==var_objetivo, var_objetivo]\n",
    "    X_train.drop([\"var_objetivo\"], axis=1, inplace=True)\n",
    "    X_test.drop([\"var_objetivo\"], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "    modelNB_random = RandomizedSearchCV(estimator = modelNB, \n",
    "                                   param_distributions=params_NB, \n",
    "                                   cv = 3,          # Validación cruzada 3-fold\n",
    "                                   verbose=2, \n",
    "                                   random_state=0, \n",
    "                                   n_jobs = -1      # Paralelizar en todos los cores disponibles\n",
    "                                   )\n",
    "    modelNB_random.fit(X_train, y_train)\n",
    "\n",
    "    ## Tomamos el mejor estimador encontrado en la búsqueda aleatoria por grilla.\n",
    "    modelNB_best_model = modelNB_random.best_estimator_\n",
    "\n",
    "    print('Los hiperparámetros del mejor modelo son:')\n",
    "    pprint(modelNB_random.best_params_)\n",
    "    print()\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    y_pred = modelNB_best_model.predict(X_test)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    specificity = tn / (tn+fp)\n",
    "    f1_score_metric = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    score_NB_train = modelNB_best_model.score(X_train, y_train)\n",
    "    score_NB_test = modelNB_best_model.score(X_test, y_test)\n",
    "    \n",
    "    resultados_modelo_metricas_df=resultados_modelo_metricas_df.append(\n",
    "        {\n",
    "            'Variable Objetivo' : var_objetivo,\n",
    "            'Modelo' : 'Naive Bayes - Gaussian' , \n",
    "            'Accuracy Train' : score_NB_train,\n",
    "            'Accuracy Test' : score_NB_test,\n",
    "            'Especificidad' : specificity,\n",
    "            'F1_score': f1_score_metric\n",
    "        },\n",
    "        ignore_index=True\n",
    "    )\n",
    "    \n",
    "    print('*'*100)\n",
    "    print(f'{var_objetivo}')\n",
    "    print('-'*100)\n",
    "\n",
    "    print(f\"Exactitud luego de búsqueda aleatoria en grilla en entrenamiento: {score_NB_train:.3f}\")\n",
    "    print(f\"Exactitud luego de búsqueda aleatoria en grilla en validación: {score_NB_test:.3f}\")\n",
    "    print('.'*50)\n",
    "    print('Especificidad luego de búsqueda aleatoria en validación:', specificity)\n",
    "    print('F1_score luego de búsqueda aleatoria en validación:', f1_score_metric)\n",
    "    print('*'*100)\n",
    "    end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6a93d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c9e340fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(\n",
    "    activation='relu',\n",
    "    capas_distr='7',\n",
    "    x_shape=(380,1)\n",
    "):\n",
    "    \"\"\"\n",
    "    Se tomaron las arquitecturas descritas en diferentes articulos cientificos donde se trabajó con Redes Neuronales con el mismo \n",
    "    conjunto de datos. Los articulos científicos de referencia son:\n",
    "        - Automatic Detection and Localization of Myocardial Infarction using Back Propagation Neural Networks \n",
    "          https://ieeexplore-ieee-org.ezproxybib.pucp.edu.pe/stamp/stamp.jsp?tp=&arnumber=5514664\n",
    "        \n",
    "        - Performance Analysis of Support Vector Machine and Neural Networks in Detection of Myocardial Infarction\n",
    "          https://www.sciencedirect.com/science/article/pii/S1877050915000447\n",
    "          \n",
    "        - Prediction of incident myocardial infarction using machine learning applied to harmonized electronic health record data\n",
    "          https://bmcmedinformdecismak.biomedcentral.com/track/pdf/10.1186/s12911-020-01268-x.pdf\n",
    "    \"\"\"\n",
    "    \n",
    "    # Mapeo de distribucion de neuronas por capa en Red Neuronal pasado por grilla\n",
    "    if capas_distr == '7':\n",
    "        neuronas_lst = [100,100,100,100,100,100,100]\n",
    "    if capas_distr == '3-1':\n",
    "        neuronas_lst = [50,40,30]\n",
    "    elif capas_distr == '3-2':\n",
    "        neuronas_lst = [30,40,50]\n",
    "    elif capas_distr == '3-3':\n",
    "        neuronas_lst = [16,10,4]\n",
    "    elif capas_distr == '2-1':\n",
    "        neuronas_lst = [30,15]\n",
    "    elif capas_distr == '2-2':\n",
    "        neuronas_lst = [30,40]\n",
    "    elif capas_distr == '2-3':\n",
    "        neuronas_lst = [50,60]\n",
    "    elif capas_distr == '2-4':\n",
    "        neuronas_lst = [70,80]\n",
    "        \n",
    "    # Crear arquitectura de capas de Red Reuronal según parámetro pasado por grilla\n",
    "    if capas_distr == '7':\n",
    "        model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Flatten(input_shape=x_shape),\n",
    "            tf.keras.layers.Dense(neuronas_lst[0], activation=activation),\n",
    "            tf.keras.layers.Dense(neuronas_lst[1], activation=activation),\n",
    "            tf.keras.layers.Dense(neuronas_lst[2], activation=activation),\n",
    "            tf.keras.layers.Dense(neuronas_lst[3], activation=activation),\n",
    "            tf.keras.layers.Dense(neuronas_lst[4], activation=activation),\n",
    "            tf.keras.layers.Dense(neuronas_lst[5], activation=activation),\n",
    "            tf.keras.layers.Dense(neuronas_lst[6], activation=tf.nn.softmax)\n",
    "        ])\n",
    "    elif ('3' in capas_distr):\n",
    "        model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Flatten(input_shape=x_shape),\n",
    "            tf.keras.layers.Dense(neuronas_lst[0], activation=activation),\n",
    "            tf.keras.layers.Dense(neuronas_lst[1], activation=activation),\n",
    "            tf.keras.layers.Dense(neuronas_lst[2], activation=tf.nn.softmax)\n",
    "        ])\n",
    "    elif ('2' in capas_distr):\n",
    "        model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Flatten(input_shape=x_shape),\n",
    "            tf.keras.layers.Dense(neuronas_lst[0], activation=activation),\n",
    "            tf.keras.layers.Dense(neuronas_lst[1], activation=tf.nn.softmax)\n",
    "        ])\n",
    "    # Compile model\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer= tf.optimizers.Adam(), metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "15dc42b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-29-0ecbf1b0d59b>:11: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=create_model, epochs=50, validation_split=0.0, batch_size=128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\coliverac\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Users\\coliverac\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Users\\coliverac\\Anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 236, in fit\n",
      "    return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
      "  File \"D:\\Users\\coliverac\\Anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 155, in fit\n",
      "    self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n",
      "  File \"<ipython-input-28-66222c152756>\", line 54, in create_model\n",
      "IndexError: list index out of range\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "D:\\Users\\coliverac\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.69292409 0.66230379 0.53475063 0.87876081 0.78524215 0.67993675\n",
      " 0.58844845 0.68164297        nan 0.65685482 0.95220125 0.92703698\n",
      " 0.7818949         nan 0.71311769 0.89388863 0.738267   0.51800998\n",
      " 0.54860208        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "19/19 [==============================] - 1s 4ms/step - loss: 3.0186 - accuracy: 0.4622\n",
      "Epoch 2/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.6937 - accuracy: 0.5591\n",
      "Epoch 3/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.6237 - accuracy: 0.6477\n",
      "Epoch 4/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5479 - accuracy: 0.7198\n",
      "Epoch 5/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4955 - accuracy: 0.7559\n",
      "Epoch 6/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4265 - accuracy: 0.8045\n",
      "Epoch 7/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3324 - accuracy: 0.8607\n",
      "Epoch 8/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.2653 - accuracy: 0.8989\n",
      "Epoch 9/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1851 - accuracy: 0.9379\n",
      "Epoch 10/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1366 - accuracy: 0.9551\n",
      "Epoch 11/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1059 - accuracy: 0.9639\n",
      "Epoch 12/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.0741 - accuracy: 0.9753\n",
      "Epoch 13/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.0519 - accuracy: 0.9857\n",
      "Epoch 14/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.0343 - accuracy: 0.9908\n",
      "Epoch 15/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.0210 - accuracy: 0.9966\n",
      "Epoch 16/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.0132 - accuracy: 0.9975\n",
      "Epoch 17/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.0085 - accuracy: 0.9992\n",
      "Epoch 18/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.0090 - accuracy: 0.9987\n",
      "Epoch 19/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.0047 - accuracy: 0.9992\n",
      "Epoch 20/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.4971e-04 - accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 7.5981e-04 - accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 6.6373e-04 - accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 5.8156e-04 - accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 5.5684e-04 - accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4.6374e-04 - accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 4.6620e-04 - accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3.7102e-04 - accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3.5439e-04 - accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3.2748e-04 - accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.9612e-04 - accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.6118e-04 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 2.3855e-04 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.9829e-04 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.6366e-04 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.3048e-04 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 9.7439e-05 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 7.0762e-05 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 5.3612e-05 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 4.4276e-05 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.8841e-05 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 2.4554e-05 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 1.9230e-05 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.6544e-05 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.3975e-05 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.2221e-05 - accuracy: 1.0000\n",
      "Best: 0.952201 using {'x_shape': (66,), 'capas_distr': '7', 'activation': 'relu'}\n",
      "0.692924 (0.051196) with: {'x_shape': (66,), 'capas_distr': '2-1', 'activation': 'relu'}\n",
      "0.662304 (0.052721) with: {'x_shape': (66,), 'capas_distr': '2-4', 'activation': 'tanh'}\n",
      "0.534751 (0.111162) with: {'x_shape': (66,), 'capas_distr': '2-1', 'activation': 'sigmoid'}\n",
      "0.878761 (0.052652) with: {'x_shape': (66,), 'capas_distr': '3-2', 'activation': 'relu'}\n",
      "0.785242 (0.023568) with: {'x_shape': (66,), 'capas_distr': '2-4', 'activation': 'relu'}\n",
      "0.679937 (0.036976) with: {'x_shape': (66,), 'capas_distr': '2-2', 'activation': 'relu'}\n",
      "0.588448 (0.094556) with: {'x_shape': (66,), 'capas_distr': '2-4', 'activation': 'sigmoid'}\n",
      "0.681643 (0.045458) with: {'x_shape': (66,), 'capas_distr': '3-2', 'activation': 'tanh'}\n",
      "nan (nan) with: {'x_shape': (66,), 'capas_distr': '2-3', 'activation': 'relu'}\n",
      "0.656855 (0.046984) with: {'x_shape': (66,), 'capas_distr': '2-1', 'activation': 'tanh'}\n",
      "0.952201 (0.039453) with: {'x_shape': (66,), 'capas_distr': '7', 'activation': 'relu'}\n",
      "0.927037 (0.047824) with: {'x_shape': (66,), 'capas_distr': '7', 'activation': 'tanh'}\n",
      "0.781895 (0.043670) with: {'x_shape': (66,), 'capas_distr': '3-3', 'activation': 'relu'}\n",
      "nan (nan) with: {'x_shape': (66,), 'capas_distr': '2-3', 'activation': 'tanh'}\n",
      "0.713118 (0.044963) with: {'x_shape': (66,), 'capas_distr': '3-3', 'activation': 'tanh'}\n",
      "0.893889 (0.056073) with: {'x_shape': (66,), 'capas_distr': '3-1', 'activation': 'relu'}\n",
      "0.738267 (0.056490) with: {'x_shape': (66,), 'capas_distr': '3-1', 'activation': 'tanh'}\n",
      "0.518010 (0.163533) with: {'x_shape': (66,), 'capas_distr': '3-3', 'activation': 'sigmoid'}\n",
      "0.548602 (0.098851) with: {'x_shape': (66,), 'capas_distr': '3-2', 'activation': 'sigmoid'}\n",
      "nan (nan) with: {'x_shape': (66,), 'capas_distr': '2-3', 'activation': 'sigmoid'}\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 1.1302e-05 - accuracy: 1.0000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 2.2908 - accuracy: 0.8588\n",
      "****************************************************************************************************\n",
      "FIBR_PREDS\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Exactitud luego de búsqueda aleatoria en grilla en entrenamiento: 1.000\n",
      "Exactitud luego de búsqueda aleatoria en grilla en validación: 0.859\n",
      "..................................................\n",
      "Especificidad luego de búsqueda aleatoria aleatoria en validación: 0.9283387622149837\n",
      "F1_score luego de búsqueda aleatoria en validación: 0.8547263314972089\n",
      "****************************************************************************************************\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-29-0ecbf1b0d59b>:11: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=create_model, epochs=50, validation_split=0.0, batch_size=128)\n",
      "D:\\Users\\coliverac\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Users\\coliverac\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Users\\coliverac\\Anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 236, in fit\n",
      "    return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
      "  File \"D:\\Users\\coliverac\\Anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 155, in fit\n",
      "    self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n",
      "  File \"<ipython-input-28-66222c152756>\", line 54, in create_model\n",
      "IndexError: list index out of range\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "D:\\Users\\coliverac\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.95046238 0.88870519 0.72580879 0.98132751 0.96913487 0.93065504\n",
      " 0.75823191 0.92071756        nan 0.87191639 0.99238095 0.98247255\n",
      " 0.97294075        nan 0.90585749 0.98437804 0.93559941 0.6800429\n",
      " 0.74219339        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "21/21 [==============================] - 1s 4ms/step - loss: 3.2450 - accuracy: 0.4413\n",
      "Epoch 2/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.6787 - accuracy: 0.5614\n",
      "Epoch 3/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.5708 - accuracy: 0.6728\n",
      "Epoch 4/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.3252 - accuracy: 0.8600\n",
      "Epoch 5/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.1331 - accuracy: 0.9649\n",
      "Epoch 6/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.0501 - accuracy: 0.9889\n",
      "Epoch 7/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.0170 - accuracy: 0.9969\n",
      "Epoch 8/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.0078 - accuracy: 0.9981\n",
      "Epoch 9/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 0.9989\n",
      "Epoch 10/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 0.9996\n",
      "Epoch 11/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 12/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.2078e-04 - accuracy: 1.0000\n",
      "Epoch 13/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.9795e-04 - accuracy: 1.0000\n",
      "Epoch 14/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.6469e-04 - accuracy: 1.0000\n",
      "Epoch 15/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4.0283e-04 - accuracy: 1.0000\n",
      "Epoch 16/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2.8904e-04 - accuracy: 1.0000\n",
      "Epoch 17/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2.1330e-04 - accuracy: 1.0000\n",
      "Epoch 18/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.6060e-04 - accuracy: 1.0000\n",
      "Epoch 19/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.2553e-04 - accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.6524e-05 - accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.7518e-05 - accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.2977e-05 - accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.2673e-05 - accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4.4207e-05 - accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3.8001e-05 - accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3.3154e-05 - accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2.8844e-05 - accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2.5553e-05 - accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2.3058e-05 - accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2.0532e-05 - accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.8635e-05 - accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.7104e-05 - accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.5830e-05 - accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.4307e-05 - accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.3163e-05 - accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.2211e-05 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.1330e-05 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.0582e-05 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.8806e-06 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.2589e-06 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.7268e-06 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.1870e-06 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.6287e-06 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.2548e-06 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 6.8739e-06 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 6.4984e-06 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.2053e-06 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.9161e-06 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.6112e-06 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.3129e-06 - accuracy: 1.0000\n",
      "Best: 0.992381 using {'x_shape': (59,), 'capas_distr': '7', 'activation': 'relu'}\n",
      "0.950462 (0.047836) with: {'x_shape': (59,), 'capas_distr': '2-1', 'activation': 'relu'}\n",
      "0.888705 (0.078590) with: {'x_shape': (59,), 'capas_distr': '2-4', 'activation': 'tanh'}\n",
      "0.725809 (0.072034) with: {'x_shape': (59,), 'capas_distr': '2-1', 'activation': 'sigmoid'}\n",
      "0.981328 (0.018364) with: {'x_shape': (59,), 'capas_distr': '3-2', 'activation': 'relu'}\n",
      "0.969135 (0.030244) with: {'x_shape': (59,), 'capas_distr': '2-4', 'activation': 'relu'}\n",
      "0.930655 (0.072878) with: {'x_shape': (59,), 'capas_distr': '2-2', 'activation': 'relu'}\n",
      "0.758232 (0.071138) with: {'x_shape': (59,), 'capas_distr': '2-4', 'activation': 'sigmoid'}\n",
      "0.920718 (0.054429) with: {'x_shape': (59,), 'capas_distr': '3-2', 'activation': 'tanh'}\n",
      "nan (nan) with: {'x_shape': (59,), 'capas_distr': '2-3', 'activation': 'relu'}\n",
      "0.871916 (0.070540) with: {'x_shape': (59,), 'capas_distr': '2-1', 'activation': 'tanh'}\n",
      "0.992381 (0.009409) with: {'x_shape': (59,), 'capas_distr': '7', 'activation': 'relu'}\n",
      "0.982473 (0.017923) with: {'x_shape': (59,), 'capas_distr': '7', 'activation': 'tanh'}\n",
      "0.972941 (0.023559) with: {'x_shape': (59,), 'capas_distr': '3-3', 'activation': 'relu'}\n",
      "nan (nan) with: {'x_shape': (59,), 'capas_distr': '2-3', 'activation': 'tanh'}\n",
      "0.905857 (0.069148) with: {'x_shape': (59,), 'capas_distr': '3-3', 'activation': 'tanh'}\n",
      "0.984378 (0.016534) with: {'x_shape': (59,), 'capas_distr': '3-1', 'activation': 'relu'}\n",
      "0.935599 (0.060929) with: {'x_shape': (59,), 'capas_distr': '3-1', 'activation': 'tanh'}\n",
      "0.680043 (0.124814) with: {'x_shape': (59,), 'capas_distr': '3-3', 'activation': 'sigmoid'}\n",
      "0.742193 (0.078341) with: {'x_shape': (59,), 'capas_distr': '3-2', 'activation': 'sigmoid'}\n",
      "nan (nan) with: {'x_shape': (59,), 'capas_distr': '2-3', 'activation': 'sigmoid'}\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 5.1579e-06 - accuracy: 1.0000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3127 - accuracy: 0.9794\n",
      "****************************************************************************************************\n",
      "PREDS_TAH\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Exactitud luego de búsqueda aleatoria en grilla en entrenamiento: 1.000\n",
      "Exactitud luego de búsqueda aleatoria en grilla en validación: 0.979\n",
      "..................................................\n",
      "Especificidad luego de búsqueda aleatoria aleatoria en validación: 0.9940298507462687\n",
      "F1_score luego de búsqueda aleatoria en validación: 0.9750458875972381\n",
      "****************************************************************************************************\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-29-0ecbf1b0d59b>:11: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=create_model, epochs=50, validation_split=0.0, batch_size=128)\n",
      "D:\\Users\\coliverac\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Users\\coliverac\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Users\\coliverac\\Anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 236, in fit\n",
      "    return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
      "  File \"D:\\Users\\coliverac\\Anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 155, in fit\n",
      "    self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n",
      "  File \"<ipython-input-28-66222c152756>\", line 54, in create_model\n",
      "IndexError: list index out of range\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "D:\\Users\\coliverac\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.92417495 0.87498388 0.78087581 0.96943908 0.95319074 0.9233885\n",
      " 0.79635417 0.9307461         nan 0.86801614 0.98839459 0.96789168\n",
      " 0.95319148        nan 0.90556881 0.97253385 0.94119474 0.79250296\n",
      " 0.8130231         nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "21/21 [==============================] - 1s 5ms/step - loss: 2.6702 - accuracy: 0.4797\n",
      "Epoch 2/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.6581 - accuracy: 0.6136\n",
      "Epoch 3/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.5164 - accuracy: 0.7658\n",
      "Epoch 4/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.3514 - accuracy: 0.8560\n",
      "Epoch 5/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.2720 - accuracy: 0.8885\n",
      "Epoch 6/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.1693 - accuracy: 0.9493\n",
      "Epoch 7/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0977 - accuracy: 0.9702\n",
      "Epoch 8/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0631 - accuracy: 0.9845\n",
      "Epoch 9/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0374 - accuracy: 0.9903\n",
      "Epoch 10/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0181 - accuracy: 0.9965\n",
      "Epoch 11/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0110 - accuracy: 0.9973\n",
      "Epoch 12/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0088 - accuracy: 0.9969\n",
      "Epoch 13/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0064 - accuracy: 0.9985\n",
      "Epoch 14/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 15/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 16/50\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 9.3240e-04 - accuracy: 1.0000\n",
      "Epoch 17/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.6379e-04 - accuracy: 1.0000\n",
      "Epoch 18/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.3167e-04 - accuracy: 1.0000\n",
      "Epoch 19/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.6628e-04 - accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 4.2277e-04 - accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 3.5680e-04 - accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 3.1618e-04 - accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 2.7938e-04 - accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2.3862e-04 - accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.6973e-04 - accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.5081e-04 - accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.0025e-04 - accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.8248e-05 - accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.3463e-05 - accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 4.3753e-05 - accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 3.4781e-05 - accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 3.0117e-05 - accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2.5384e-05 - accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2.1899e-05 - accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.9503e-05 - accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.7148e-05 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.5400e-05 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.3842e-05 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.2396e-05 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.1515e-05 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.0414e-05 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.5518e-06 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.8741e-06 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.2277e-06 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.6856e-06 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.1524e-06 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.7641e-06 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.3410e-06 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.9686e-06 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.6365e-06 - accuracy: 1.0000\n",
      "Best: 0.988395 using {'x_shape': (62,), 'capas_distr': '7', 'activation': 'relu'}\n",
      "0.924175 (0.075521) with: {'x_shape': (62,), 'capas_distr': '2-1', 'activation': 'relu'}\n",
      "0.874984 (0.056486) with: {'x_shape': (62,), 'capas_distr': '2-4', 'activation': 'tanh'}\n",
      "0.780876 (0.042268) with: {'x_shape': (62,), 'capas_distr': '2-1', 'activation': 'sigmoid'}\n",
      "0.969439 (0.029875) with: {'x_shape': (62,), 'capas_distr': '3-2', 'activation': 'relu'}\n",
      "0.953191 (0.048616) with: {'x_shape': (62,), 'capas_distr': '2-4', 'activation': 'relu'}\n",
      "0.923389 (0.056983) with: {'x_shape': (62,), 'capas_distr': '2-2', 'activation': 'relu'}\n",
      "0.796354 (0.047443) with: {'x_shape': (62,), 'capas_distr': '2-4', 'activation': 'sigmoid'}\n",
      "0.930746 (0.055534) with: {'x_shape': (62,), 'capas_distr': '3-2', 'activation': 'tanh'}\n",
      "nan (nan) with: {'x_shape': (62,), 'capas_distr': '2-3', 'activation': 'relu'}\n",
      "0.868016 (0.050874) with: {'x_shape': (62,), 'capas_distr': '2-1', 'activation': 'tanh'}\n",
      "0.988395 (0.011670) with: {'x_shape': (62,), 'capas_distr': '7', 'activation': 'relu'}\n",
      "0.967892 (0.032218) with: {'x_shape': (62,), 'capas_distr': '7', 'activation': 'tanh'}\n",
      "0.953191 (0.045779) with: {'x_shape': (62,), 'capas_distr': '3-3', 'activation': 'relu'}\n",
      "nan (nan) with: {'x_shape': (62,), 'capas_distr': '2-3', 'activation': 'tanh'}\n",
      "0.905569 (0.056871) with: {'x_shape': (62,), 'capas_distr': '3-3', 'activation': 'tanh'}\n",
      "0.972534 (0.025672) with: {'x_shape': (62,), 'capas_distr': '3-1', 'activation': 'relu'}\n",
      "0.941195 (0.049681) with: {'x_shape': (62,), 'capas_distr': '3-1', 'activation': 'tanh'}\n",
      "0.792503 (0.051540) with: {'x_shape': (62,), 'capas_distr': '3-3', 'activation': 'sigmoid'}\n",
      "0.813023 (0.047901) with: {'x_shape': (62,), 'capas_distr': '3-2', 'activation': 'sigmoid'}\n",
      "nan (nan) with: {'x_shape': (62,), 'capas_distr': '2-3', 'activation': 'sigmoid'}\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 5.4058e-06 - accuracy: 1.0000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4842 - accuracy: 0.9618\n",
      "****************************************************************************************************\n",
      "JELUD_TAH\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Exactitud luego de búsqueda aleatoria en grilla en entrenamiento: 1.000\n",
      "Exactitud luego de búsqueda aleatoria en grilla en validación: 0.962\n",
      "..................................................\n",
      "Especificidad luego de búsqueda aleatoria aleatoria en validación: 0.9819819819819819\n",
      "F1_score luego de búsqueda aleatoria en validación: 0.9603227797865773\n",
      "****************************************************************************************************\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-29-0ecbf1b0d59b>:11: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=create_model, epochs=50, validation_split=0.0, batch_size=128)\n",
      "D:\\Users\\coliverac\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Users\\coliverac\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Users\\coliverac\\Anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 236, in fit\n",
      "    return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
      "  File \"D:\\Users\\coliverac\\Anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 155, in fit\n",
      "    self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n",
      "  File \"<ipython-input-28-66222c152756>\", line 54, in create_model\n",
      "IndexError: list index out of range\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "D:\\Users\\coliverac\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.89132323 0.83440118 0.73114835 0.94744558 0.92821295 0.87365538\n",
      " 0.76020185 0.88074425        nan 0.83205901 0.97882352 0.95881966\n",
      " 0.91840749        nan 0.86974459 0.97254901 0.89055202 0.57479179\n",
      " 0.7743642         nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "20/20 [==============================] - 1s 5ms/step - loss: 3.0527 - accuracy: 0.4470\n",
      "Epoch 2/50\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.7020 - accuracy: 0.5522\n",
      "Epoch 3/50\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.6060 - accuracy: 0.7041\n",
      "Epoch 4/50\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4485 - accuracy: 0.7951\n",
      "Epoch 5/50\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.3136 - accuracy: 0.8768\n",
      "Epoch 6/50\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2458 - accuracy: 0.9105\n",
      "Epoch 7/50\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.1468 - accuracy: 0.9505\n",
      "Epoch 8/50\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.0922 - accuracy: 0.9753\n",
      "Epoch 9/50\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.0562 - accuracy: 0.9851\n",
      "Epoch 10/50\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.0365 - accuracy: 0.9918\n",
      "Epoch 11/50\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.0220 - accuracy: 0.9953\n",
      "Epoch 12/50\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.0165 - accuracy: 0.9949\n",
      "Epoch 13/50\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 0.9988\n",
      "Epoch 14/50\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 15/50\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 16/50\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 7.5028e-04 - accuracy: 1.0000\n",
      "Epoch 17/50\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 5.1865e-04 - accuracy: 1.0000\n",
      "Epoch 18/50\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3.9750e-04 - accuracy: 1.0000\n",
      "Epoch 19/50\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3.1661e-04 - accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2.5596e-04 - accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2.0975e-04 - accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1.7760e-04 - accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1.5288e-04 - accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1.3331e-04 - accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1.1523e-04 - accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1.0384e-04 - accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 9.0276e-05 - accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 8.0062e-05 - accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 7.0985e-05 - accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 6.3907e-05 - accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 5.6547e-05 - accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 5.0425e-05 - accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4.5221e-05 - accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4.0388e-05 - accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3.6712e-05 - accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 3.2921e-05 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2.9647e-05 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2.7300e-05 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2.4360e-05 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2.2165e-05 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 2.0663e-05 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1.8960e-05 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1.7069e-05 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.5792e-05 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.4562e-05 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1.3499e-05 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1.2487e-05 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.1638e-05 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1.0926e-05 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 1.0181e-05 - accuracy: 1.0000\n",
      "Best: 0.978824 using {'x_shape': (59,), 'capas_distr': '7', 'activation': 'relu'}\n",
      "0.891323 (0.054636) with: {'x_shape': (59,), 'capas_distr': '2-1', 'activation': 'relu'}\n",
      "0.834401 (0.047121) with: {'x_shape': (59,), 'capas_distr': '2-4', 'activation': 'tanh'}\n",
      "0.731148 (0.041896) with: {'x_shape': (59,), 'capas_distr': '2-1', 'activation': 'sigmoid'}\n",
      "0.947446 (0.042221) with: {'x_shape': (59,), 'capas_distr': '3-2', 'activation': 'relu'}\n",
      "0.928213 (0.041807) with: {'x_shape': (59,), 'capas_distr': '2-4', 'activation': 'relu'}\n",
      "0.873655 (0.051395) with: {'x_shape': (59,), 'capas_distr': '2-2', 'activation': 'relu'}\n",
      "0.760202 (0.036158) with: {'x_shape': (59,), 'capas_distr': '2-4', 'activation': 'sigmoid'}\n",
      "0.880744 (0.067721) with: {'x_shape': (59,), 'capas_distr': '3-2', 'activation': 'tanh'}\n",
      "nan (nan) with: {'x_shape': (59,), 'capas_distr': '2-3', 'activation': 'relu'}\n",
      "0.832059 (0.056088) with: {'x_shape': (59,), 'capas_distr': '2-1', 'activation': 'tanh'}\n",
      "0.978824 (0.020050) with: {'x_shape': (59,), 'capas_distr': '7', 'activation': 'relu'}\n",
      "0.958820 (0.034206) with: {'x_shape': (59,), 'capas_distr': '7', 'activation': 'tanh'}\n",
      "0.918407 (0.047889) with: {'x_shape': (59,), 'capas_distr': '3-3', 'activation': 'relu'}\n",
      "nan (nan) with: {'x_shape': (59,), 'capas_distr': '2-3', 'activation': 'tanh'}\n",
      "0.869745 (0.064491) with: {'x_shape': (59,), 'capas_distr': '3-3', 'activation': 'tanh'}\n",
      "0.972549 (0.027141) with: {'x_shape': (59,), 'capas_distr': '3-1', 'activation': 'relu'}\n",
      "0.890552 (0.062064) with: {'x_shape': (59,), 'capas_distr': '3-1', 'activation': 'tanh'}\n",
      "0.574792 (0.289024) with: {'x_shape': (59,), 'capas_distr': '3-3', 'activation': 'sigmoid'}\n",
      "0.774364 (0.057976) with: {'x_shape': (59,), 'capas_distr': '3-2', 'activation': 'sigmoid'}\n",
      "nan (nan) with: {'x_shape': (59,), 'capas_distr': '2-3', 'activation': 'sigmoid'}\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 9.6912e-06 - accuracy: 1.0000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9225 - accuracy: 0.9324\n",
      "****************************************************************************************************\n",
      "FIBR_JELUD\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Exactitud luego de búsqueda aleatoria en grilla en entrenamiento: 1.000\n",
      "Exactitud luego de búsqueda aleatoria en grilla en validación: 0.932\n",
      "..................................................\n",
      "Especificidad luego de búsqueda aleatoria aleatoria en validación: 0.9813664596273292\n",
      "F1_score luego de búsqueda aleatoria en validación: 0.918038616973507\n",
      "****************************************************************************************************\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-29-0ecbf1b0d59b>:11: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=create_model, epochs=50, validation_split=0.0, batch_size=128)\n",
      "D:\\Users\\coliverac\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Users\\coliverac\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Users\\coliverac\\Anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 236, in fit\n",
      "    return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
      "  File \"D:\\Users\\coliverac\\Anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 155, in fit\n",
      "    self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n",
      "  File \"<ipython-input-28-66222c152756>\", line 54, in create_model\n",
      "IndexError: list index out of range\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "D:\\Users\\coliverac\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.86967136 0.82945449 0.76660727 0.9395346  0.91221141 0.86068774\n",
      " 0.78964196 0.85951054        nan 0.81929444 0.98049921 0.96411351\n",
      " 0.90558449        nan 0.84740115 0.96841344 0.85913286 0.7486804\n",
      " 0.75961561        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "21/21 [==============================] - 1s 3ms/step - loss: 2.8458 - accuracy: 0.4434\n",
      "Epoch 2/50\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.6736 - accuracy: 0.5578\n",
      "Epoch 3/50\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.5165 - accuracy: 0.8009\n",
      "Epoch 4/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.4730 - accuracy: 0.7904\n",
      "Epoch 5/50\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3250 - accuracy: 0.8806\n",
      "Epoch 6/50\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2585 - accuracy: 0.9067\n",
      "Epoch 7/50\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1957 - accuracy: 0.9329\n",
      "Epoch 8/50\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1430 - accuracy: 0.9528\n",
      "Epoch 9/50\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1735 - accuracy: 0.9375\n",
      "Epoch 10/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.0706 - accuracy: 0.9836\n",
      "Epoch 11/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.0496 - accuracy: 0.9887\n",
      "Epoch 12/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.0346 - accuracy: 0.9922\n",
      "Epoch 13/50\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0276 - accuracy: 0.9930\n",
      "Epoch 14/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.0194 - accuracy: 0.9965\n",
      "Epoch 15/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.0108 - accuracy: 0.9980\n",
      "Epoch 16/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.0066 - accuracy: 0.9988\n",
      "Epoch 17/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.9996\n",
      "Epoch 18/50\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 0.9996\n",
      "Epoch 19/50\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.3168e-04 - accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 5.5832e-04 - accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.9865e-04 - accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4.9164e-04 - accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2.7246e-04 - accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.4204e-04 - accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2.1348e-04 - accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.9708e-04 - accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.6594e-04 - accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.4874e-04 - accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.3977e-04 - accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.2496e-04 - accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.1389e-04 - accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.0351e-04 - accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.9901e-05 - accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.7556e-05 - accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.2489e-05 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.4828e-05 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.0103e-05 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.4917e-05 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.3735e-05 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.7026e-05 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.3430e-05 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4.9606e-05 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4.6127e-05 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 4.3754e-05 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4.0246e-05 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3.7668e-05 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3.5861e-05 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3.4019e-05 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3.2618e-05 - accuracy: 1.0000\n",
      "Best: 0.980499 using {'x_shape': (54,), 'capas_distr': '7', 'activation': 'relu'}\n",
      "0.869671 (0.041347) with: {'x_shape': (54,), 'capas_distr': '2-1', 'activation': 'relu'}\n",
      "0.829454 (0.031204) with: {'x_shape': (54,), 'capas_distr': '2-4', 'activation': 'tanh'}\n",
      "0.766607 (0.035307) with: {'x_shape': (54,), 'capas_distr': '2-1', 'activation': 'sigmoid'}\n",
      "0.939535 (0.041382) with: {'x_shape': (54,), 'capas_distr': '3-2', 'activation': 'relu'}\n",
      "0.912211 (0.035934) with: {'x_shape': (54,), 'capas_distr': '2-4', 'activation': 'relu'}\n",
      "0.860688 (0.034742) with: {'x_shape': (54,), 'capas_distr': '2-2', 'activation': 'relu'}\n",
      "0.789642 (0.048058) with: {'x_shape': (54,), 'capas_distr': '2-4', 'activation': 'sigmoid'}\n",
      "0.859511 (0.030577) with: {'x_shape': (54,), 'capas_distr': '3-2', 'activation': 'tanh'}\n",
      "nan (nan) with: {'x_shape': (54,), 'capas_distr': '2-3', 'activation': 'relu'}\n",
      "0.819294 (0.042113) with: {'x_shape': (54,), 'capas_distr': '2-1', 'activation': 'tanh'}\n",
      "0.980499 (0.017823) with: {'x_shape': (54,), 'capas_distr': '7', 'activation': 'relu'}\n",
      "0.964114 (0.026220) with: {'x_shape': (54,), 'capas_distr': '7', 'activation': 'tanh'}\n",
      "0.905584 (0.045324) with: {'x_shape': (54,), 'capas_distr': '3-3', 'activation': 'relu'}\n",
      "nan (nan) with: {'x_shape': (54,), 'capas_distr': '2-3', 'activation': 'tanh'}\n",
      "0.847401 (0.036698) with: {'x_shape': (54,), 'capas_distr': '3-3', 'activation': 'tanh'}\n",
      "0.968413 (0.031679) with: {'x_shape': (54,), 'capas_distr': '3-1', 'activation': 'relu'}\n",
      "0.859133 (0.047841) with: {'x_shape': (54,), 'capas_distr': '3-1', 'activation': 'tanh'}\n",
      "0.748680 (0.057400) with: {'x_shape': (54,), 'capas_distr': '3-3', 'activation': 'sigmoid'}\n",
      "0.759616 (0.062317) with: {'x_shape': (54,), 'capas_distr': '3-2', 'activation': 'sigmoid'}\n",
      "nan (nan) with: {'x_shape': (54,), 'capas_distr': '2-3', 'activation': 'sigmoid'}\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 3.1182e-05 - accuracy: 1.0000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6292 - accuracy: 0.9382\n",
      "****************************************************************************************************\n",
      "A_V_BLOK\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Exactitud luego de búsqueda aleatoria en grilla en entrenamiento: 1.000\n",
      "Exactitud luego de búsqueda aleatoria en grilla en validación: 0.938\n",
      "..................................................\n",
      "Especificidad luego de búsqueda aleatoria aleatoria en validación: 0.9696048632218845\n",
      "F1_score luego de búsqueda aleatoria en validación: 0.9368115683299115\n",
      "****************************************************************************************************\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-29-0ecbf1b0d59b>:11: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=create_model, epochs=50, validation_split=0.0, batch_size=128)\n",
      "D:\\Users\\coliverac\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Users\\coliverac\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Users\\coliverac\\Anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 236, in fit\n",
      "    return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
      "  File \"D:\\Users\\coliverac\\Anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 155, in fit\n",
      "    self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n",
      "  File \"<ipython-input-28-66222c152756>\", line 54, in create_model\n",
      "IndexError: list index out of range\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "D:\\Users\\coliverac\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.77416667 0.71125001 0.57791667 0.88666667 0.82958333 0.725\n",
      " 0.61208334 0.7275            nan 0.67708334 0.95958333 0.92083333\n",
      " 0.80791667        nan 0.73208334 0.92958333 0.72875    0.46541667\n",
      " 0.55458334        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 3.3159 - accuracy: 0.4117\n",
      "Epoch 2/50\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.7482 - accuracy: 0.5129\n",
      "Epoch 3/50\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.6570 - accuracy: 0.6054\n",
      "Epoch 4/50\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.6043 - accuracy: 0.6629\n",
      "Epoch 5/50\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5279 - accuracy: 0.7387\n",
      "Epoch 6/50\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4380 - accuracy: 0.8079\n",
      "Epoch 7/50\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.3543 - accuracy: 0.8629\n",
      "Epoch 8/50\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.2893 - accuracy: 0.8971\n",
      "Epoch 9/50\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.2027 - accuracy: 0.9287\n",
      "Epoch 10/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1425 - accuracy: 0.9533\n",
      "Epoch 11/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1049 - accuracy: 0.9700\n",
      "Epoch 12/50\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0776 - accuracy: 0.9737\n",
      "Epoch 13/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0544 - accuracy: 0.9846\n",
      "Epoch 14/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0490 - accuracy: 0.9854\n",
      "Epoch 15/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0344 - accuracy: 0.9912\n",
      "Epoch 16/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0249 - accuracy: 0.9929\n",
      "Epoch 17/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0203 - accuracy: 0.9933\n",
      "Epoch 18/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0280 - accuracy: 0.9908\n",
      "Epoch 19/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0200 - accuracy: 0.9950\n",
      "Epoch 20/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0160 - accuracy: 0.9954\n",
      "Epoch 21/50\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0105 - accuracy: 0.9962\n",
      "Epoch 22/50\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0080 - accuracy: 0.9992\n",
      "Epoch 23/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 0.9983\n",
      "Epoch 24/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0056 - accuracy: 0.9983\n",
      "Epoch 25/50\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 7.4956e-04 - accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4.9530e-04 - accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3.7183e-04 - accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3.0174e-04 - accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2.2831e-04 - accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 1.8885e-04 - accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 1.8208e-04 - accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 1.1529e-04 - accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1.0032e-04 - accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.2954e-05 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.1548e-05 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 7.0325e-05 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 7.0470e-05 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 6.0887e-05 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 5.9948e-05 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 4.6999e-05 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 4.0063e-05 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 3.6350e-05 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 3.5040e-05 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 3.1054e-05 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 2.9851e-05 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2.7735e-05 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2.5434e-05 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 2.3739e-05 - accuracy: 1.0000\n",
      "Best: 0.959583 using {'x_shape': (71,), 'capas_distr': '7', 'activation': 'relu'}\n",
      "0.774167 (0.063719) with: {'x_shape': (71,), 'capas_distr': '2-1', 'activation': 'relu'}\n",
      "0.711250 (0.046297) with: {'x_shape': (71,), 'capas_distr': '2-4', 'activation': 'tanh'}\n",
      "0.577917 (0.094231) with: {'x_shape': (71,), 'capas_distr': '2-1', 'activation': 'sigmoid'}\n",
      "0.886667 (0.019257) with: {'x_shape': (71,), 'capas_distr': '3-2', 'activation': 'relu'}\n",
      "0.829583 (0.054937) with: {'x_shape': (71,), 'capas_distr': '2-4', 'activation': 'relu'}\n",
      "0.725000 (0.070686) with: {'x_shape': (71,), 'capas_distr': '2-2', 'activation': 'relu'}\n",
      "0.612083 (0.083066) with: {'x_shape': (71,), 'capas_distr': '2-4', 'activation': 'sigmoid'}\n",
      "0.727500 (0.045898) with: {'x_shape': (71,), 'capas_distr': '3-2', 'activation': 'tanh'}\n",
      "nan (nan) with: {'x_shape': (71,), 'capas_distr': '2-3', 'activation': 'relu'}\n",
      "0.677083 (0.060352) with: {'x_shape': (71,), 'capas_distr': '2-1', 'activation': 'tanh'}\n",
      "0.959583 (0.034349) with: {'x_shape': (71,), 'capas_distr': '7', 'activation': 'relu'}\n",
      "0.920833 (0.056565) with: {'x_shape': (71,), 'capas_distr': '7', 'activation': 'tanh'}\n",
      "0.807917 (0.047733) with: {'x_shape': (71,), 'capas_distr': '3-3', 'activation': 'relu'}\n",
      "nan (nan) with: {'x_shape': (71,), 'capas_distr': '2-3', 'activation': 'tanh'}\n",
      "0.732083 (0.040560) with: {'x_shape': (71,), 'capas_distr': '3-3', 'activation': 'tanh'}\n",
      "0.929583 (0.037786) with: {'x_shape': (71,), 'capas_distr': '3-1', 'activation': 'relu'}\n",
      "0.728750 (0.034796) with: {'x_shape': (71,), 'capas_distr': '3-1', 'activation': 'tanh'}\n",
      "0.465417 (0.195650) with: {'x_shape': (71,), 'capas_distr': '3-3', 'activation': 'sigmoid'}\n",
      "0.554583 (0.132428) with: {'x_shape': (71,), 'capas_distr': '3-2', 'activation': 'sigmoid'}\n",
      "nan (nan) with: {'x_shape': (71,), 'capas_distr': '2-3', 'activation': 'sigmoid'}\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.2177e-05 - accuracy: 1.0000\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.5904 - accuracy: 0.8971\n",
      "****************************************************************************************************\n",
      "OTEK_LANC\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Exactitud luego de búsqueda aleatoria en grilla en entrenamiento: 1.000\n",
      "Exactitud luego de búsqueda aleatoria en grilla en validación: 0.897\n",
      "..................................................\n",
      "Especificidad luego de búsqueda aleatoria aleatoria en validación: 0.9741935483870968\n",
      "F1_score luego de búsqueda aleatoria en validación: 0.8747370240893791\n",
      "****************************************************************************************************\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-29-0ecbf1b0d59b>:11: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=create_model, epochs=50, validation_split=0.0, batch_size=128)\n",
      "D:\\Users\\coliverac\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Users\\coliverac\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Users\\coliverac\\Anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 236, in fit\n",
      "    return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
      "  File \"D:\\Users\\coliverac\\Anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 155, in fit\n",
      "    self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n",
      "  File \"<ipython-input-28-66222c152756>\", line 54, in create_model\n",
      "IndexError: list index out of range\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "D:\\Users\\coliverac\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.86779209 0.83618878 0.74960481 0.95867066 0.92044424 0.85609542\n",
      " 0.78665556 0.8841892         nan 0.82020285 0.98596492 0.96178576\n",
      " 0.89779941        nan 0.8560962  0.97076025 0.87716861 0.70633072\n",
      " 0.77143717        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "21/21 [==============================] - 1s 4ms/step - loss: 3.5146 - accuracy: 0.4762\n",
      "Epoch 2/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.8401 - accuracy: 0.4949\n",
      "Epoch 3/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.6538 - accuracy: 0.6872\n",
      "Epoch 4/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.5507 - accuracy: 0.6985\n",
      "Epoch 5/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.3312 - accuracy: 0.8627\n",
      "Epoch 6/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.2294 - accuracy: 0.9080\n",
      "Epoch 7/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.1202 - accuracy: 0.9583\n",
      "Epoch 8/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0823 - accuracy: 0.9735\n",
      "Epoch 9/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0389 - accuracy: 0.9914\n",
      "Epoch 10/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0255 - accuracy: 0.9953\n",
      "Epoch 11/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0240 - accuracy: 0.9953\n",
      "Epoch 12/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0129 - accuracy: 0.9969\n",
      "Epoch 13/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0077 - accuracy: 0.9992\n",
      "Epoch 14/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0101 - accuracy: 0.9980\n",
      "Epoch 15/50\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0058 - accuracy: 0.9988\n",
      "Epoch 16/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0074 - accuracy: 0.9984\n",
      "Epoch 17/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0041 - accuracy: 0.9988\n",
      "Epoch 18/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0026 - accuracy: 0.9996\n",
      "Epoch 19/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.3503e-04 - accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.6835e-04 - accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 3.4529e-04 - accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 3.1190e-04 - accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2.6407e-04 - accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2.0706e-04 - accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.7060e-04 - accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.4821e-04 - accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.3021e-04 - accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.1661e-04 - accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.0632e-04 - accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 9.4466e-05 - accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 8.4743e-05 - accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.8681e-05 - accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 7.0899e-05 - accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.5720e-05 - accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.0832e-05 - accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.6410e-05 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.2894e-05 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 4.8987e-05 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 4.5710e-05 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 4.2543e-05 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 4.0383e-05 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 3.7949e-05 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3.5690e-05 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3.3883e-05 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3.2288e-05 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2.9779e-05 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2.7827e-05 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2.6607e-05 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2.5396e-05 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2.4613e-05 - accuracy: 1.0000\n",
      "Best: 0.985965 using {'x_shape': (50,), 'capas_distr': '7', 'activation': 'relu'}\n",
      "0.867792 (0.039783) with: {'x_shape': (50,), 'capas_distr': '2-1', 'activation': 'relu'}\n",
      "0.836189 (0.052147) with: {'x_shape': (50,), 'capas_distr': '2-4', 'activation': 'tanh'}\n",
      "0.749605 (0.060978) with: {'x_shape': (50,), 'capas_distr': '2-1', 'activation': 'sigmoid'}\n",
      "0.958671 (0.022841) with: {'x_shape': (50,), 'capas_distr': '3-2', 'activation': 'relu'}\n",
      "0.920444 (0.040681) with: {'x_shape': (50,), 'capas_distr': '2-4', 'activation': 'relu'}\n",
      "0.856095 (0.044600) with: {'x_shape': (50,), 'capas_distr': '2-2', 'activation': 'relu'}\n",
      "0.786656 (0.051313) with: {'x_shape': (50,), 'capas_distr': '2-4', 'activation': 'sigmoid'}\n",
      "0.884189 (0.057693) with: {'x_shape': (50,), 'capas_distr': '3-2', 'activation': 'tanh'}\n",
      "nan (nan) with: {'x_shape': (50,), 'capas_distr': '2-3', 'activation': 'relu'}\n",
      "0.820203 (0.048245) with: {'x_shape': (50,), 'capas_distr': '2-1', 'activation': 'tanh'}\n",
      "0.985965 (0.011526) with: {'x_shape': (50,), 'capas_distr': '7', 'activation': 'relu'}\n",
      "0.961786 (0.031586) with: {'x_shape': (50,), 'capas_distr': '7', 'activation': 'tanh'}\n",
      "0.897799 (0.043618) with: {'x_shape': (50,), 'capas_distr': '3-3', 'activation': 'relu'}\n",
      "nan (nan) with: {'x_shape': (50,), 'capas_distr': '2-3', 'activation': 'tanh'}\n",
      "0.856096 (0.052547) with: {'x_shape': (50,), 'capas_distr': '3-3', 'activation': 'tanh'}\n",
      "0.970760 (0.029768) with: {'x_shape': (50,), 'capas_distr': '3-1', 'activation': 'relu'}\n",
      "0.877169 (0.052956) with: {'x_shape': (50,), 'capas_distr': '3-1', 'activation': 'tanh'}\n",
      "0.706331 (0.074598) with: {'x_shape': (50,), 'capas_distr': '3-3', 'activation': 'sigmoid'}\n",
      "0.771437 (0.046574) with: {'x_shape': (50,), 'capas_distr': '3-2', 'activation': 'sigmoid'}\n",
      "nan (nan) with: {'x_shape': (50,), 'capas_distr': '2-3', 'activation': 'sigmoid'}\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.3308e-05 - accuracy: 1.0000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7422 - accuracy: 0.9618\n",
      "****************************************************************************************************\n",
      "RAZRIV\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Exactitud luego de búsqueda aleatoria en grilla en entrenamiento: 1.000\n",
      "Exactitud luego de búsqueda aleatoria en grilla en validación: 0.962\n",
      "..................................................\n",
      "Especificidad luego de búsqueda aleatoria aleatoria en validación: 0.9848942598187311\n",
      "F1_score luego de búsqueda aleatoria en validación: 0.9580274214949138\n",
      "****************************************************************************************************\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-29-0ecbf1b0d59b>:11: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=create_model, epochs=50, validation_split=0.0, batch_size=128)\n",
      "D:\\Users\\coliverac\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Users\\coliverac\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Users\\coliverac\\Anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 236, in fit\n",
      "    return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
      "  File \"D:\\Users\\coliverac\\Anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 155, in fit\n",
      "    self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n",
      "  File \"<ipython-input-28-66222c152756>\", line 54, in create_model\n",
      "IndexError: list index out of range\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "D:\\Users\\coliverac\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.77368262 0.72557424 0.58872944 0.93379149 0.85651586 0.74057137\n",
      " 0.61713182 0.72637796        nan 0.67587552 0.97398858 0.94164997\n",
      " 0.8438592         nan 0.73188355 0.95546367 0.7630488  0.42583205\n",
      " 0.59346083        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "20/20 [==============================] - 1s 4ms/step - loss: 3.2236 - accuracy: 0.4890\n",
      "Epoch 2/50\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6901 - accuracy: 0.5473\n",
      "Epoch 3/50\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6336 - accuracy: 0.6274\n",
      "Epoch 4/50\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5406 - accuracy: 0.7338\n",
      "Epoch 5/50\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.4640 - accuracy: 0.7827\n",
      "Epoch 6/50\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.3715 - accuracy: 0.8352\n",
      "Epoch 7/50\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2646 - accuracy: 0.9010\n",
      "Epoch 8/50\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.2007 - accuracy: 0.9290\n",
      "Epoch 9/50\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.1296 - accuracy: 0.9602\n",
      "Epoch 10/50\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0884 - accuracy: 0.9728\n",
      "Epoch 11/50\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0541 - accuracy: 0.9874\n",
      "Epoch 12/50\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0354 - accuracy: 0.9897\n",
      "Epoch 13/50\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0255 - accuracy: 0.9945\n",
      "Epoch 14/50\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0158 - accuracy: 0.9957\n",
      "Epoch 15/50\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0103 - accuracy: 0.9972\n",
      "Epoch 16/50\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0110 - accuracy: 0.9968\n",
      "Epoch 17/50\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0189 - accuracy: 0.9929\n",
      "Epoch 18/50\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0076 - accuracy: 0.9984\n",
      "Epoch 19/50\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0032 - accuracy: 0.9996\n",
      "Epoch 20/50\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 8.2140e-04 - accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 4.9719e-04 - accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 3.8552e-04 - accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 3.3562e-04 - accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2.9721e-04 - accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2.7418e-04 - accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2.4777e-04 - accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 2.1405e-04 - accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.9771e-04 - accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.8193e-04 - accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.6856e-04 - accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.4557e-04 - accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 1.3593e-04 - accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.2275e-04 - accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.1769e-04 - accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.0514e-04 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 1.0003e-04 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 9.2380e-05 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 8.5764e-05 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 8.2038e-05 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 7.6340e-05 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 7.0304e-05 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 6.6359e-05 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 6.1790e-05 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 5.7998e-05 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 5.4773e-05 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 5.1411e-05 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4.8468e-05 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4.6047e-05 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 4.3346e-05 - accuracy: 1.0000\n",
      "Best: 0.973989 using {'x_shape': (58,), 'capas_distr': '7', 'activation': 'relu'}\n",
      "0.773683 (0.041819) with: {'x_shape': (58,), 'capas_distr': '2-1', 'activation': 'relu'}\n",
      "0.725574 (0.048264) with: {'x_shape': (58,), 'capas_distr': '2-4', 'activation': 'tanh'}\n",
      "0.588729 (0.079589) with: {'x_shape': (58,), 'capas_distr': '2-1', 'activation': 'sigmoid'}\n",
      "0.933791 (0.052523) with: {'x_shape': (58,), 'capas_distr': '3-2', 'activation': 'relu'}\n",
      "0.856516 (0.065802) with: {'x_shape': (58,), 'capas_distr': '2-4', 'activation': 'relu'}\n",
      "0.740571 (0.049661) with: {'x_shape': (58,), 'capas_distr': '2-2', 'activation': 'relu'}\n",
      "0.617132 (0.064894) with: {'x_shape': (58,), 'capas_distr': '2-4', 'activation': 'sigmoid'}\n",
      "0.726378 (0.062269) with: {'x_shape': (58,), 'capas_distr': '3-2', 'activation': 'tanh'}\n",
      "nan (nan) with: {'x_shape': (58,), 'capas_distr': '2-3', 'activation': 'relu'}\n",
      "0.675876 (0.050363) with: {'x_shape': (58,), 'capas_distr': '2-1', 'activation': 'tanh'}\n",
      "0.973989 (0.023547) with: {'x_shape': (58,), 'capas_distr': '7', 'activation': 'relu'}\n",
      "0.941650 (0.030057) with: {'x_shape': (58,), 'capas_distr': '7', 'activation': 'tanh'}\n",
      "0.843859 (0.078241) with: {'x_shape': (58,), 'capas_distr': '3-3', 'activation': 'relu'}\n",
      "nan (nan) with: {'x_shape': (58,), 'capas_distr': '2-3', 'activation': 'tanh'}\n",
      "0.731884 (0.035054) with: {'x_shape': (58,), 'capas_distr': '3-3', 'activation': 'tanh'}\n",
      "0.955464 (0.038484) with: {'x_shape': (58,), 'capas_distr': '3-1', 'activation': 'relu'}\n",
      "0.763049 (0.070853) with: {'x_shape': (58,), 'capas_distr': '3-1', 'activation': 'tanh'}\n",
      "0.425832 (0.228893) with: {'x_shape': (58,), 'capas_distr': '3-3', 'activation': 'sigmoid'}\n",
      "0.593461 (0.071462) with: {'x_shape': (58,), 'capas_distr': '3-2', 'activation': 'sigmoid'}\n",
      "nan (nan) with: {'x_shape': (58,), 'capas_distr': '2-3', 'activation': 'sigmoid'}\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 4.1495e-05 - accuracy: 1.0000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.2904 - accuracy: 0.9176\n",
      "****************************************************************************************************\n",
      "DRESSLER\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Exactitud luego de búsqueda aleatoria en grilla en entrenamiento: 1.000\n",
      "Exactitud luego de búsqueda aleatoria en grilla en validación: 0.918\n",
      "..................................................\n",
      "Especificidad luego de búsqueda aleatoria aleatoria en validación: 0.9629629629629629\n",
      "F1_score luego de búsqueda aleatoria en validación: 0.9120173222663299\n",
      "****************************************************************************************************\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-29-0ecbf1b0d59b>:11: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=create_model, epochs=50, validation_split=0.0, batch_size=128)\n",
      "D:\\Users\\coliverac\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Users\\coliverac\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Users\\coliverac\\Anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 236, in fit\n",
      "    return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
      "  File \"D:\\Users\\coliverac\\Anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 155, in fit\n",
      "    self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n",
      "  File \"<ipython-input-28-66222c152756>\", line 54, in create_model\n",
      "IndexError: list index out of range\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "D:\\Users\\coliverac\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.60247345 0.56202599 0.46992345 0.68434869 0.66535993 0.59225328\n",
      " 0.50401875 0.60882914        nan 0.54399027 0.8676126  0.78864518\n",
      " 0.66191205        nan 0.59514806 0.78185747 0.6126853  0.29064507\n",
      " 0.30338615        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 3.3400 - accuracy: 0.4335\n",
      "Epoch 2/50\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.7507 - accuracy: 0.5080\n",
      "Epoch 3/50\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.7269 - accuracy: 0.5222\n",
      "Epoch 4/50\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6786 - accuracy: 0.5889\n",
      "Epoch 5/50\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6756 - accuracy: 0.5665\n",
      "Epoch 6/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6707 - accuracy: 0.5757\n",
      "Epoch 7/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6320 - accuracy: 0.6434\n",
      "Epoch 8/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5985 - accuracy: 0.6780\n",
      "Epoch 9/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6554 - accuracy: 0.6347\n",
      "Epoch 10/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5589 - accuracy: 0.7238\n",
      "Epoch 11/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5139 - accuracy: 0.7540\n",
      "Epoch 12/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4849 - accuracy: 0.7740\n",
      "Epoch 13/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.4140 - accuracy: 0.8290\n",
      "Epoch 14/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3676 - accuracy: 0.8485\n",
      "Epoch 15/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3369 - accuracy: 0.8622\n",
      "Epoch 16/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.3095 - accuracy: 0.8709\n",
      "Epoch 17/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2441 - accuracy: 0.8987\n",
      "Epoch 18/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2423 - accuracy: 0.9031\n",
      "Epoch 19/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.2700 - accuracy: 0.8919\n",
      "Epoch 20/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1786 - accuracy: 0.9372\n",
      "Epoch 21/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1460 - accuracy: 0.9479\n",
      "Epoch 22/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1654 - accuracy: 0.9333\n",
      "Epoch 23/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1330 - accuracy: 0.9552\n",
      "Epoch 24/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0966 - accuracy: 0.9669\n",
      "Epoch 25/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0921 - accuracy: 0.9674\n",
      "Epoch 26/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0863 - accuracy: 0.9669\n",
      "Epoch 27/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0779 - accuracy: 0.9722\n",
      "Epoch 28/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0565 - accuracy: 0.9795\n",
      "Epoch 29/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0623 - accuracy: 0.9810\n",
      "Epoch 30/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0473 - accuracy: 0.9844\n",
      "Epoch 31/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0337 - accuracy: 0.9883\n",
      "Epoch 32/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0229 - accuracy: 0.9937\n",
      "Epoch 33/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0168 - accuracy: 0.9956\n",
      "Epoch 34/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0121 - accuracy: 0.9971\n",
      "Epoch 35/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0107 - accuracy: 0.9971\n",
      "Epoch 36/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0159 - accuracy: 0.9937\n",
      "Epoch 37/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0075 - accuracy: 0.9981\n",
      "Epoch 38/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.9956\n",
      "Epoch 39/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0163 - accuracy: 0.9942\n",
      "Epoch 40/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0264 - accuracy: 0.9888\n",
      "Epoch 41/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0131 - accuracy: 0.9956\n",
      "Epoch 42/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0498 - accuracy: 0.9800\n",
      "Epoch 43/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0320 - accuracy: 0.9903\n",
      "Epoch 44/50\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0199 - accuracy: 0.9937\n",
      "Epoch 45/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0162 - accuracy: 0.9917\n",
      "Epoch 46/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0137 - accuracy: 0.9942\n",
      "Epoch 47/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0125 - accuracy: 0.9951\n",
      "Epoch 48/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0127 - accuracy: 0.9942\n",
      "Epoch 49/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0212 - accuracy: 0.9903\n",
      "Epoch 50/50\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0985 - accuracy: 0.9659\n",
      "Best: 0.867613 using {'x_shape': (78,), 'capas_distr': '7', 'activation': 'relu'}\n",
      "0.602473 (0.057785) with: {'x_shape': (78,), 'capas_distr': '2-1', 'activation': 'relu'}\n",
      "0.562026 (0.101864) with: {'x_shape': (78,), 'capas_distr': '2-4', 'activation': 'tanh'}\n",
      "0.469923 (0.130532) with: {'x_shape': (78,), 'capas_distr': '2-1', 'activation': 'sigmoid'}\n",
      "0.684349 (0.064692) with: {'x_shape': (78,), 'capas_distr': '3-2', 'activation': 'relu'}\n",
      "0.665360 (0.050465) with: {'x_shape': (78,), 'capas_distr': '2-4', 'activation': 'relu'}\n",
      "0.592253 (0.075956) with: {'x_shape': (78,), 'capas_distr': '2-2', 'activation': 'relu'}\n",
      "0.504019 (0.129563) with: {'x_shape': (78,), 'capas_distr': '2-4', 'activation': 'sigmoid'}\n",
      "0.608829 (0.051170) with: {'x_shape': (78,), 'capas_distr': '3-2', 'activation': 'tanh'}\n",
      "nan (nan) with: {'x_shape': (78,), 'capas_distr': '2-3', 'activation': 'relu'}\n",
      "0.543990 (0.106554) with: {'x_shape': (78,), 'capas_distr': '2-1', 'activation': 'tanh'}\n",
      "0.867613 (0.087440) with: {'x_shape': (78,), 'capas_distr': '7', 'activation': 'relu'}\n",
      "0.788645 (0.047878) with: {'x_shape': (78,), 'capas_distr': '7', 'activation': 'tanh'}\n",
      "0.661912 (0.076881) with: {'x_shape': (78,), 'capas_distr': '3-3', 'activation': 'relu'}\n",
      "nan (nan) with: {'x_shape': (78,), 'capas_distr': '2-3', 'activation': 'tanh'}\n",
      "0.595148 (0.092381) with: {'x_shape': (78,), 'capas_distr': '3-3', 'activation': 'tanh'}\n",
      "0.781857 (0.063683) with: {'x_shape': (78,), 'capas_distr': '3-1', 'activation': 'relu'}\n",
      "0.612685 (0.068528) with: {'x_shape': (78,), 'capas_distr': '3-1', 'activation': 'tanh'}\n",
      "0.290645 (0.156017) with: {'x_shape': (78,), 'capas_distr': '3-3', 'activation': 'sigmoid'}\n",
      "0.303386 (0.170780) with: {'x_shape': (78,), 'capas_distr': '3-2', 'activation': 'sigmoid'}\n",
      "nan (nan) with: {'x_shape': (78,), 'capas_distr': '2-3', 'activation': 'sigmoid'}\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.0849 - accuracy: 0.9693\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.5195 - accuracy: 0.7000\n",
      "****************************************************************************************************\n",
      "ZSN\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Exactitud luego de búsqueda aleatoria en grilla en entrenamiento: 0.969\n",
      "Exactitud luego de búsqueda aleatoria en grilla en validación: 0.700\n",
      "..................................................\n",
      "Especificidad luego de búsqueda aleatoria aleatoria en validación: 0.8764940239043825\n",
      "F1_score luego de búsqueda aleatoria en validación: 0.6675918498315417\n",
      "****************************************************************************************************\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-29-0ecbf1b0d59b>:11: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=create_model, epochs=50, validation_split=0.0, batch_size=128)\n",
      "D:\\Users\\coliverac\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Users\\coliverac\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Users\\coliverac\\Anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 236, in fit\n",
      "    return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
      "  File \"D:\\Users\\coliverac\\Anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 155, in fit\n",
      "    self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n",
      "  File \"<ipython-input-28-66222c152756>\", line 54, in create_model\n",
      "IndexError: list index out of range\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "D:\\Users\\coliverac\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.6785339  0.6093901  0.50879977 0.8306869  0.77577782 0.63329211\n",
      " 0.54567159 0.66092559        nan 0.59010552 0.942598   0.89818426\n",
      " 0.76151154        nan 0.63958317 0.88937923 0.67939528 0.36581318\n",
      " 0.4405156         nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "19/19 [==============================] - 1s 4ms/step - loss: 3.2515 - accuracy: 0.3567\n",
      "Epoch 2/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.6962 - accuracy: 0.5516\n",
      "Epoch 3/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.7357 - accuracy: 0.5050\n",
      "Epoch 4/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.6519 - accuracy: 0.5956\n",
      "Epoch 5/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5813 - accuracy: 0.6886\n",
      "Epoch 6/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5066 - accuracy: 0.7573\n",
      "Epoch 7/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4439 - accuracy: 0.8034\n",
      "Epoch 8/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3726 - accuracy: 0.8378\n",
      "Epoch 9/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.2890 - accuracy: 0.8843\n",
      "Epoch 10/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.2468 - accuracy: 0.8919\n",
      "Epoch 11/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1749 - accuracy: 0.9371\n",
      "Epoch 12/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1269 - accuracy: 0.9568\n",
      "Epoch 13/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1041 - accuracy: 0.9640\n",
      "Epoch 14/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0983 - accuracy: 0.9627\n",
      "Epoch 15/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0643 - accuracy: 0.9765\n",
      "Epoch 16/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0666 - accuracy: 0.9778\n",
      "Epoch 17/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0452 - accuracy: 0.9883\n",
      "Epoch 18/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0322 - accuracy: 0.9899\n",
      "Epoch 19/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0303 - accuracy: 0.9895\n",
      "Epoch 20/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0261 - accuracy: 0.9912\n",
      "Epoch 21/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0130 - accuracy: 0.9971\n",
      "Epoch 22/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0093 - accuracy: 0.9983\n",
      "Epoch 23/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 0.9992\n",
      "Epoch 24/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 0.9996\n",
      "Epoch 25/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.2470e-04 - accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 6.9161e-04 - accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 5.9696e-04 - accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 5.4080e-04 - accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4.7031e-04 - accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3.9458e-04 - accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3.4646e-04 - accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3.1050e-04 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2.9411e-04 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2.6789e-04 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2.4105e-04 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2.2219e-04 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2.0168e-04 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1.8991e-04 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1.7311e-04 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1.6351e-04 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1.5191e-04 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1.4037e-04 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1.3394e-04 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1.2480e-04 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1.2305e-04 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1.0991e-04 - accuracy: 1.0000\n",
      "Best: 0.942598 using {'x_shape': (78,), 'capas_distr': '7', 'activation': 'relu'}\n",
      "0.678534 (0.045953) with: {'x_shape': (78,), 'capas_distr': '2-1', 'activation': 'relu'}\n",
      "0.609390 (0.040535) with: {'x_shape': (78,), 'capas_distr': '2-4', 'activation': 'tanh'}\n",
      "0.508800 (0.064947) with: {'x_shape': (78,), 'capas_distr': '2-1', 'activation': 'sigmoid'}\n",
      "0.830687 (0.036665) with: {'x_shape': (78,), 'capas_distr': '3-2', 'activation': 'relu'}\n",
      "0.775778 (0.060707) with: {'x_shape': (78,), 'capas_distr': '2-4', 'activation': 'relu'}\n",
      "0.633292 (0.038158) with: {'x_shape': (78,), 'capas_distr': '2-2', 'activation': 'relu'}\n",
      "0.545672 (0.063185) with: {'x_shape': (78,), 'capas_distr': '2-4', 'activation': 'sigmoid'}\n",
      "0.660926 (0.043855) with: {'x_shape': (78,), 'capas_distr': '3-2', 'activation': 'tanh'}\n",
      "nan (nan) with: {'x_shape': (78,), 'capas_distr': '2-3', 'activation': 'relu'}\n",
      "0.590106 (0.056629) with: {'x_shape': (78,), 'capas_distr': '2-1', 'activation': 'tanh'}\n",
      "0.942598 (0.046987) with: {'x_shape': (78,), 'capas_distr': '7', 'activation': 'relu'}\n",
      "0.898184 (0.059594) with: {'x_shape': (78,), 'capas_distr': '7', 'activation': 'tanh'}\n",
      "0.761512 (0.036351) with: {'x_shape': (78,), 'capas_distr': '3-3', 'activation': 'relu'}\n",
      "nan (nan) with: {'x_shape': (78,), 'capas_distr': '2-3', 'activation': 'tanh'}\n",
      "0.639583 (0.030064) with: {'x_shape': (78,), 'capas_distr': '3-3', 'activation': 'tanh'}\n",
      "0.889379 (0.064571) with: {'x_shape': (78,), 'capas_distr': '3-1', 'activation': 'relu'}\n",
      "0.679395 (0.032168) with: {'x_shape': (78,), 'capas_distr': '3-1', 'activation': 'tanh'}\n",
      "0.365813 (0.219164) with: {'x_shape': (78,), 'capas_distr': '3-3', 'activation': 'sigmoid'}\n",
      "0.440516 (0.096224) with: {'x_shape': (78,), 'capas_distr': '3-2', 'activation': 'sigmoid'}\n",
      "nan (nan) with: {'x_shape': (78,), 'capas_distr': '2-3', 'activation': 'sigmoid'}\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.0346e-04 - accuracy: 1.0000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.9340 - accuracy: 0.8647\n",
      "****************************************************************************************************\n",
      "REC_IM\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Exactitud luego de búsqueda aleatoria en grilla en entrenamiento: 1.000\n",
      "Exactitud luego de búsqueda aleatoria en grilla en validación: 0.865\n",
      "..................................................\n",
      "Especificidad luego de búsqueda aleatoria aleatoria en validación: 0.9240506329113924\n",
      "F1_score luego de búsqueda aleatoria en validación: 0.8671970121381888\n",
      "****************************************************************************************************\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-29-0ecbf1b0d59b>:11: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=create_model, epochs=50, validation_split=0.0, batch_size=128)\n",
      "D:\\Users\\coliverac\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Users\\coliverac\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Users\\coliverac\\Anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 236, in fit\n",
      "    return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
      "  File \"D:\\Users\\coliverac\\Anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 155, in fit\n",
      "    self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n",
      "  File \"<ipython-input-28-66222c152756>\", line 54, in create_model\n",
      "IndexError: list index out of range\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "D:\\Users\\coliverac\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.72848245 0.66681041 0.5562762  0.86219907 0.77442808 0.7152328\n",
      " 0.60429137 0.69496006        nan 0.6440335  0.95572352 0.90358384\n",
      " 0.76987406        nan 0.69453998 0.9114385  0.73015844 0.38813546\n",
      " 0.53804818        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "19/19 [==============================] - 1s 4ms/step - loss: 3.3751 - accuracy: 0.4309\n",
      "Epoch 2/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.7491 - accuracy: 0.5087\n",
      "Epoch 3/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.6838 - accuracy: 0.5484\n",
      "Epoch 4/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.6290 - accuracy: 0.6312\n",
      "Epoch 5/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5363 - accuracy: 0.7450\n",
      "Epoch 6/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4788 - accuracy: 0.7802\n",
      "Epoch 7/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4060 - accuracy: 0.8158\n",
      "Epoch 8/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3321 - accuracy: 0.8560\n",
      "Epoch 9/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.2516 - accuracy: 0.9036\n",
      "Epoch 10/50\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.2178 - accuracy: 0.9168\n",
      "Epoch 11/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1545 - accuracy: 0.9478\n",
      "Epoch 12/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1178 - accuracy: 0.9582\n",
      "Epoch 13/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.1051 - accuracy: 0.9644\n",
      "Epoch 14/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0831 - accuracy: 0.9706\n",
      "Epoch 15/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0730 - accuracy: 0.9760\n",
      "Epoch 16/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0458 - accuracy: 0.9859\n",
      "Epoch 17/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0398 - accuracy: 0.9888\n",
      "Epoch 18/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0407 - accuracy: 0.9880\n",
      "Epoch 19/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0398 - accuracy: 0.9872\n",
      "Epoch 20/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.0218 - accuracy: 0.9917\n",
      "Epoch 21/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0151 - accuracy: 0.9971\n",
      "Epoch 22/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0101 - accuracy: 0.9979\n",
      "Epoch 23/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0101 - accuracy: 0.9975\n",
      "Epoch 24/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0113 - accuracy: 0.9959\n",
      "Epoch 25/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 0.9975\n",
      "Epoch 26/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0065 - accuracy: 0.9979\n",
      "Epoch 27/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0072 - accuracy: 0.9983\n",
      "Epoch 28/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 0.9996\n",
      "Epoch 29/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 6.7313e-04 - accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 5.6271e-04 - accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4.1125e-04 - accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3.7735e-04 - accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3.2632e-04 - accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3.0078e-04 - accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2.9212e-04 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2.5435e-04 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2.3301e-04 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2.1533e-04 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2.0283e-04 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1.8363e-04 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1.7293e-04 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1.5963e-04 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1.4443e-04 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1.3523e-04 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1.2530e-04 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1.1237e-04 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.6890e-05 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 7.6962e-05 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 6.3719e-05 - accuracy: 1.0000\n",
      "Best: 0.955724 using {'x_shape': (68,), 'capas_distr': '7', 'activation': 'relu'}\n",
      "0.728482 (0.067680) with: {'x_shape': (68,), 'capas_distr': '2-1', 'activation': 'relu'}\n",
      "0.666810 (0.027361) with: {'x_shape': (68,), 'capas_distr': '2-4', 'activation': 'tanh'}\n",
      "0.556276 (0.073243) with: {'x_shape': (68,), 'capas_distr': '2-1', 'activation': 'sigmoid'}\n",
      "0.862199 (0.066164) with: {'x_shape': (68,), 'capas_distr': '3-2', 'activation': 'relu'}\n",
      "0.774428 (0.059544) with: {'x_shape': (68,), 'capas_distr': '2-4', 'activation': 'relu'}\n",
      "0.715233 (0.035914) with: {'x_shape': (68,), 'capas_distr': '2-2', 'activation': 'relu'}\n",
      "0.604291 (0.041881) with: {'x_shape': (68,), 'capas_distr': '2-4', 'activation': 'sigmoid'}\n",
      "0.694960 (0.027242) with: {'x_shape': (68,), 'capas_distr': '3-2', 'activation': 'tanh'}\n",
      "nan (nan) with: {'x_shape': (68,), 'capas_distr': '2-3', 'activation': 'relu'}\n",
      "0.644034 (0.025270) with: {'x_shape': (68,), 'capas_distr': '2-1', 'activation': 'tanh'}\n",
      "0.955724 (0.036749) with: {'x_shape': (68,), 'capas_distr': '7', 'activation': 'relu'}\n",
      "0.903584 (0.053289) with: {'x_shape': (68,), 'capas_distr': '7', 'activation': 'tanh'}\n",
      "0.769874 (0.020725) with: {'x_shape': (68,), 'capas_distr': '3-3', 'activation': 'relu'}\n",
      "nan (nan) with: {'x_shape': (68,), 'capas_distr': '2-3', 'activation': 'tanh'}\n",
      "0.694540 (0.026748) with: {'x_shape': (68,), 'capas_distr': '3-3', 'activation': 'tanh'}\n",
      "0.911439 (0.047453) with: {'x_shape': (68,), 'capas_distr': '3-1', 'activation': 'relu'}\n",
      "0.730158 (0.044645) with: {'x_shape': (68,), 'capas_distr': '3-1', 'activation': 'tanh'}\n",
      "0.388135 (0.299734) with: {'x_shape': (68,), 'capas_distr': '3-3', 'activation': 'sigmoid'}\n",
      "0.538048 (0.133153) with: {'x_shape': (68,), 'capas_distr': '3-2', 'activation': 'sigmoid'}\n",
      "nan (nan) with: {'x_shape': (68,), 'capas_distr': '2-3', 'activation': 'sigmoid'}\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 5.4221e-05 - accuracy: 1.0000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.8689 - accuracy: 0.8588\n",
      "****************************************************************************************************\n",
      "P_IM_STEN\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Exactitud luego de búsqueda aleatoria en grilla en entrenamiento: 1.000\n",
      "Exactitud luego de búsqueda aleatoria en grilla en validación: 0.859\n",
      "..................................................\n",
      "Especificidad luego de búsqueda aleatoria aleatoria en validación: 0.9326923076923077\n",
      "F1_score luego de búsqueda aleatoria en validación: 0.8510252100840338\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "for var_objetivo in var_objetivo_lst:\n",
    "    # Lectura\n",
    "    X_train = X_TRAIN_DF.loc[X_TRAIN_DF[\"var_objetivo\"]==var_objetivo].dropna(axis='columns')\n",
    "    y_train = Y_TRAIN_DF.loc[Y_TRAIN_DF[\"var_objetivo\"]==var_objetivo, var_objetivo]\n",
    "    X_test = X_TEST_DF.loc[X_TEST_DF[\"var_objetivo\"]==var_objetivo].dropna(axis='columns')\n",
    "    y_test = Y_TEST_DF.loc[Y_TEST_DF[\"var_objetivo\"]==var_objetivo, var_objetivo]\n",
    "    X_train.drop([\"var_objetivo\"], axis=1, inplace=True)\n",
    "    X_test.drop([\"var_objetivo\"], axis=1, inplace=True)\n",
    "    \n",
    "    # Crear Modelo con Clasificador de Keras - Redes Neuronales en base a función genérica\n",
    "    model = KerasClassifier(build_fn=create_model, epochs=50, validation_split=0.0, batch_size=128)\n",
    "    # Se define la grilla de búsqueda.\n",
    "    # - Función de activación\n",
    "    f_activacion = ['relu', 'tanh', 'sigmoid']\n",
    "    # - Se contempla diferentes arquitecturas de redes neuronales tomados de la literatura\n",
    "    capas_distr = ['7','3-1','3-2','3-3','2-1','2-2','2-3','2-4']\n",
    "    # - Se contempla la dimensión de entrada del X\n",
    "    x_shape = [X_train.iloc[0].shape]\n",
    "\n",
    "    param_grid = dict(activation=f_activacion,capas_distr=capas_distr,x_shape=x_shape)\n",
    "\n",
    "\n",
    "    random_grid = RandomizedSearchCV(estimator=model, \n",
    "                                     param_distributions = param_grid, \n",
    "                                     cv = 5,          # Validación cruzada 10-fold\n",
    "                                     verbose=2, \n",
    "                                     random_state=2022, \n",
    "                                     n_iter = 20,\n",
    "                                     n_jobs = -1)\n",
    "    modelRN_random = random_grid.fit(X_train, y_train)\n",
    "\n",
    "    # Resumen de Resultados\n",
    "    print(\"Mejor: %f usando %s\" % (random_grid.best_score_, random_grid.best_params_))\n",
    "    means = modelRN_random.cv_results_['mean_test_score']\n",
    "    stds = modelRN_random.cv_results_['std_test_score']\n",
    "    params = modelRN_random.cv_results_['params']\n",
    "    for mean, stdev, param in zip(means, stds, params):\n",
    "        print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "    ## Tomamos el mejor estimador encontrado en la búsqueda aleatoria por grilla.\n",
    "    modelRN_best_model = modelRN_random.best_estimator_\n",
    "    \n",
    "    train_acc = modelRN_best_model.score(X_train, y_train)\n",
    "    test_acc = modelRN_best_model.score(X_test, y_test)\n",
    "    \n",
    "    y_pred = modelRN_best_model.predict(X_test)\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    specificity = tn / (tn+fp)\n",
    "    f1_score_metric = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    resultados_modelo_metricas_df=resultados_modelo_metricas_df.append(\n",
    "        {\n",
    "            'Variable Objetivo' : var_objetivo,\n",
    "            'Modelo' : 'Redes Neuronales' , \n",
    "            'Accuracy Train' : train_acc,\n",
    "            'Accuracy Test' : test_acc,\n",
    "            'Especificidad' : specificity,\n",
    "            'F1_score': f1_score_metric\n",
    "        },\n",
    "        ignore_index=True\n",
    "    )\n",
    "    \n",
    "    print('*'*100)\n",
    "    print(f'{var_objetivo}')\n",
    "    print('-'*100)\n",
    "    print(f\"Exactitud luego de búsqueda aleatoria en grilla en entrenamiento: {train_acc:.3f}\")\n",
    "    print(f\"Exactitud luego de búsqueda aleatoria en grilla en validación: {test_acc:.3f}\")\n",
    "    print('.'*50)\n",
    "    print('Especificidad luego de búsqueda aleatoria aleatoria en validación:', specificity)\n",
    "    print('F1_score luego de búsqueda aleatoria en validación:', f1_score_metric)\n",
    "    print('*'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f146cde9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable Objetivo</th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Accuracy Train</th>\n",
       "      <th>Accuracy Test</th>\n",
       "      <th>Especificidad</th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FIBR_PREDS</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.897059</td>\n",
       "      <td>0.983713</td>\n",
       "      <td>0.867688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PREDS_TAH</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.998093</td>\n",
       "      <td>0.985294</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JELUD_TAH</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979412</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.969225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FIBR_JELUD</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.997253</td>\n",
       "      <td>0.944118</td>\n",
       "      <td>0.996894</td>\n",
       "      <td>0.919836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A_V_BLOK</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.958553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>OTEK_LANC</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.990323</td>\n",
       "      <td>0.883997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RAZRIV</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.998830</td>\n",
       "      <td>0.967647</td>\n",
       "      <td>0.993958</td>\n",
       "      <td>0.957522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DRESSLER</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.947059</td>\n",
       "      <td>0.993827</td>\n",
       "      <td>0.927030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ZSN</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.779412</td>\n",
       "      <td>0.964143</td>\n",
       "      <td>0.738701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>REC_IM</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.920588</td>\n",
       "      <td>0.990506</td>\n",
       "      <td>0.890983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>P_IM_STEN</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.908824</td>\n",
       "      <td>0.987179</td>\n",
       "      <td>0.878671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>FIBR_PREDS</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.999581</td>\n",
       "      <td>0.879412</td>\n",
       "      <td>0.967427</td>\n",
       "      <td>0.853268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PREDS_TAH</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.997330</td>\n",
       "      <td>0.985294</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>JELUD_TAH</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.998451</td>\n",
       "      <td>0.967647</td>\n",
       "      <td>0.987988</td>\n",
       "      <td>0.963308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>FIBR_JELUD</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.981554</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.990683</td>\n",
       "      <td>0.923086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A_V_BLOK</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.998829</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.958553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>OTEK_LANC</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.991667</td>\n",
       "      <td>0.888235</td>\n",
       "      <td>0.974194</td>\n",
       "      <td>0.857797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RAZRIV</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.996490</td>\n",
       "      <td>0.964706</td>\n",
       "      <td>0.990937</td>\n",
       "      <td>0.956041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>DRESSLER</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.991719</td>\n",
       "      <td>0.952941</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.929979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ZSN</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.883585</td>\n",
       "      <td>0.782353</td>\n",
       "      <td>0.984064</td>\n",
       "      <td>0.730870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>REC_IM</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.992456</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.977848</td>\n",
       "      <td>0.890795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>P_IM_STEN</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.987169</td>\n",
       "      <td>0.905882</td>\n",
       "      <td>0.983974</td>\n",
       "      <td>0.877035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>FIBR_PREDS</td>\n",
       "      <td>SVM</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.811765</td>\n",
       "      <td>0.882736</td>\n",
       "      <td>0.820697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>PREDS_TAH</td>\n",
       "      <td>SVM</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.973529</td>\n",
       "      <td>0.985075</td>\n",
       "      <td>0.974713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>JELUD_TAH</td>\n",
       "      <td>SVM</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.955882</td>\n",
       "      <td>0.975976</td>\n",
       "      <td>0.957320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>FIBR_JELUD</td>\n",
       "      <td>SVM</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.920588</td>\n",
       "      <td>0.959627</td>\n",
       "      <td>0.919515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>A_V_BLOK</td>\n",
       "      <td>SVM</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.929412</td>\n",
       "      <td>0.957447</td>\n",
       "      <td>0.934626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>OTEK_LANC</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.999167</td>\n",
       "      <td>0.864706</td>\n",
       "      <td>0.932258</td>\n",
       "      <td>0.860308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>RAZRIV</td>\n",
       "      <td>SVM</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.952941</td>\n",
       "      <td>0.978852</td>\n",
       "      <td>0.950071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>DRESSLER</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.999211</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.893382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ZSN</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.992694</td>\n",
       "      <td>0.652941</td>\n",
       "      <td>0.788845</td>\n",
       "      <td>0.644448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>REC_IM</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.999162</td>\n",
       "      <td>0.811765</td>\n",
       "      <td>0.863924</td>\n",
       "      <td>0.837950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>P_IM_STEN</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.996689</td>\n",
       "      <td>0.835294</td>\n",
       "      <td>0.900641</td>\n",
       "      <td>0.842464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>FIBR_PREDS</td>\n",
       "      <td>Naive Bayes - Gaussian</td>\n",
       "      <td>0.717701</td>\n",
       "      <td>0.605882</td>\n",
       "      <td>0.615635</td>\n",
       "      <td>0.686267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>PREDS_TAH</td>\n",
       "      <td>Naive Bayes - Gaussian</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.429412</td>\n",
       "      <td>0.429851</td>\n",
       "      <td>0.589021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>JELUD_TAH</td>\n",
       "      <td>Naive Bayes - Gaussian</td>\n",
       "      <td>0.820751</td>\n",
       "      <td>0.770588</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.852603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>FIBR_JELUD</td>\n",
       "      <td>Naive Bayes - Gaussian</td>\n",
       "      <td>0.785322</td>\n",
       "      <td>0.717647</td>\n",
       "      <td>0.723602</td>\n",
       "      <td>0.795154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>A_V_BLOK</td>\n",
       "      <td>Naive Bayes - Gaussian</td>\n",
       "      <td>0.727557</td>\n",
       "      <td>0.544118</td>\n",
       "      <td>0.537994</td>\n",
       "      <td>0.676008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>OTEK_LANC</td>\n",
       "      <td>Naive Bayes - Gaussian</td>\n",
       "      <td>0.665417</td>\n",
       "      <td>0.514706</td>\n",
       "      <td>0.496774</td>\n",
       "      <td>0.611610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>RAZRIV</td>\n",
       "      <td>Naive Bayes - Gaussian</td>\n",
       "      <td>0.821373</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.764350</td>\n",
       "      <td>0.834702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>DRESSLER</td>\n",
       "      <td>Naive Bayes - Gaussian</td>\n",
       "      <td>0.720032</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.549383</td>\n",
       "      <td>0.671451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>ZSN</td>\n",
       "      <td>Naive Bayes - Gaussian</td>\n",
       "      <td>0.617146</td>\n",
       "      <td>0.417647</td>\n",
       "      <td>0.366534</td>\n",
       "      <td>0.443430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>REC_IM</td>\n",
       "      <td>Naive Bayes - Gaussian</td>\n",
       "      <td>0.657586</td>\n",
       "      <td>0.420588</td>\n",
       "      <td>0.398734</td>\n",
       "      <td>0.532019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>P_IM_STEN</td>\n",
       "      <td>Naive Bayes - Gaussian</td>\n",
       "      <td>0.701987</td>\n",
       "      <td>0.485294</td>\n",
       "      <td>0.464744</td>\n",
       "      <td>0.587617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>FIBR_PREDS</td>\n",
       "      <td>Redes Neuronales</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.858824</td>\n",
       "      <td>0.928339</td>\n",
       "      <td>0.854726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>PREDS_TAH</td>\n",
       "      <td>Redes Neuronales</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979412</td>\n",
       "      <td>0.994030</td>\n",
       "      <td>0.975046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>JELUD_TAH</td>\n",
       "      <td>Redes Neuronales</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.961765</td>\n",
       "      <td>0.981982</td>\n",
       "      <td>0.960323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>FIBR_JELUD</td>\n",
       "      <td>Redes Neuronales</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.932353</td>\n",
       "      <td>0.981366</td>\n",
       "      <td>0.918039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>A_V_BLOK</td>\n",
       "      <td>Redes Neuronales</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.938235</td>\n",
       "      <td>0.969605</td>\n",
       "      <td>0.936812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>OTEK_LANC</td>\n",
       "      <td>Redes Neuronales</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.897059</td>\n",
       "      <td>0.974194</td>\n",
       "      <td>0.874737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>RAZRIV</td>\n",
       "      <td>Redes Neuronales</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.961765</td>\n",
       "      <td>0.984894</td>\n",
       "      <td>0.958027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>DRESSLER</td>\n",
       "      <td>Redes Neuronales</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.917647</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.912017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>ZSN</td>\n",
       "      <td>Redes Neuronales</td>\n",
       "      <td>0.969313</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.876494</td>\n",
       "      <td>0.667592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>REC_IM</td>\n",
       "      <td>Redes Neuronales</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.864706</td>\n",
       "      <td>0.924051</td>\n",
       "      <td>0.867197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>P_IM_STEN</td>\n",
       "      <td>Redes Neuronales</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.858824</td>\n",
       "      <td>0.932692</td>\n",
       "      <td>0.851025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Variable Objetivo                  Modelo  Accuracy Train  Accuracy Test  \\\n",
       "0         FIBR_PREDS            RandomForest        1.000000       0.897059   \n",
       "1          PREDS_TAH            RandomForest        0.998093       0.985294   \n",
       "2          JELUD_TAH            RandomForest        1.000000       0.979412   \n",
       "3         FIBR_JELUD            RandomForest        0.997253       0.944118   \n",
       "4           A_V_BLOK            RandomForest        1.000000       0.970588   \n",
       "5          OTEK_LANC            RandomForest        1.000000       0.911765   \n",
       "6             RAZRIV            RandomForest        0.998830       0.967647   \n",
       "7           DRESSLER            RandomForest        1.000000       0.947059   \n",
       "8                ZSN            RandomForest        1.000000       0.779412   \n",
       "9             REC_IM            RandomForest        1.000000       0.920588   \n",
       "10         P_IM_STEN            RandomForest        1.000000       0.908824   \n",
       "11        FIBR_PREDS                 XGBoost        0.999581       0.879412   \n",
       "12         PREDS_TAH                 XGBoost        0.997330       0.985294   \n",
       "13         JELUD_TAH                 XGBoost        0.998451       0.967647   \n",
       "14        FIBR_JELUD                 XGBoost        0.981554       0.941176   \n",
       "15          A_V_BLOK                 XGBoost        0.998829       0.970588   \n",
       "16         OTEK_LANC                 XGBoost        0.991667       0.888235   \n",
       "17            RAZRIV                 XGBoost        0.996490       0.964706   \n",
       "18          DRESSLER                 XGBoost        0.991719       0.952941   \n",
       "19               ZSN                 XGBoost        0.883585       0.782353   \n",
       "20            REC_IM                 XGBoost        0.992456       0.911765   \n",
       "21         P_IM_STEN                 XGBoost        0.987169       0.905882   \n",
       "22        FIBR_PREDS                     SVM        1.000000       0.811765   \n",
       "23         PREDS_TAH                     SVM        1.000000       0.973529   \n",
       "24         JELUD_TAH                     SVM        1.000000       0.955882   \n",
       "25        FIBR_JELUD                     SVM        1.000000       0.920588   \n",
       "26          A_V_BLOK                     SVM        1.000000       0.929412   \n",
       "27         OTEK_LANC                     SVM        0.999167       0.864706   \n",
       "28            RAZRIV                     SVM        1.000000       0.952941   \n",
       "29          DRESSLER                     SVM        0.999211       0.882353   \n",
       "30               ZSN                     SVM        0.992694       0.652941   \n",
       "31            REC_IM                     SVM        0.999162       0.811765   \n",
       "32         P_IM_STEN                     SVM        0.996689       0.835294   \n",
       "33        FIBR_PREDS  Naive Bayes - Gaussian        0.717701       0.605882   \n",
       "34         PREDS_TAH  Naive Bayes - Gaussian        0.695652       0.429412   \n",
       "35         JELUD_TAH  Naive Bayes - Gaussian        0.820751       0.770588   \n",
       "36        FIBR_JELUD  Naive Bayes - Gaussian        0.785322       0.717647   \n",
       "37          A_V_BLOK  Naive Bayes - Gaussian        0.727557       0.544118   \n",
       "38         OTEK_LANC  Naive Bayes - Gaussian        0.665417       0.514706   \n",
       "39            RAZRIV  Naive Bayes - Gaussian        0.821373       0.750000   \n",
       "40          DRESSLER  Naive Bayes - Gaussian        0.720032       0.550000   \n",
       "41               ZSN  Naive Bayes - Gaussian        0.617146       0.417647   \n",
       "42            REC_IM  Naive Bayes - Gaussian        0.657586       0.420588   \n",
       "43         P_IM_STEN  Naive Bayes - Gaussian        0.701987       0.485294   \n",
       "44        FIBR_PREDS        Redes Neuronales        1.000000       0.858824   \n",
       "45         PREDS_TAH        Redes Neuronales        1.000000       0.979412   \n",
       "46         JELUD_TAH        Redes Neuronales        1.000000       0.961765   \n",
       "47        FIBR_JELUD        Redes Neuronales        1.000000       0.932353   \n",
       "48          A_V_BLOK        Redes Neuronales        1.000000       0.938235   \n",
       "49         OTEK_LANC        Redes Neuronales        1.000000       0.897059   \n",
       "50            RAZRIV        Redes Neuronales        1.000000       0.961765   \n",
       "51          DRESSLER        Redes Neuronales        1.000000       0.917647   \n",
       "52               ZSN        Redes Neuronales        0.969313       0.700000   \n",
       "53            REC_IM        Redes Neuronales        1.000000       0.864706   \n",
       "54         P_IM_STEN        Redes Neuronales        1.000000       0.858824   \n",
       "\n",
       "    Especificidad  F1_score  \n",
       "0        0.983713  0.867688  \n",
       "1        1.000000  0.977996  \n",
       "2        1.000000  0.969225  \n",
       "3        0.996894  0.919836  \n",
       "4        1.000000  0.958553  \n",
       "5        0.990323  0.883997  \n",
       "6        0.993958  0.957522  \n",
       "7        0.993827  0.927030  \n",
       "8        0.964143  0.738701  \n",
       "9        0.990506  0.890983  \n",
       "10       0.987179  0.878671  \n",
       "11       0.967427  0.853268  \n",
       "12       1.000000  0.977996  \n",
       "13       0.987988  0.963308  \n",
       "14       0.990683  0.923086  \n",
       "15       1.000000  0.958553  \n",
       "16       0.974194  0.857797  \n",
       "17       0.990937  0.956041  \n",
       "18       1.000000  0.929979  \n",
       "19       0.984064  0.730870  \n",
       "20       0.977848  0.890795  \n",
       "21       0.983974  0.877035  \n",
       "22       0.882736  0.820697  \n",
       "23       0.985075  0.974713  \n",
       "24       0.975976  0.957320  \n",
       "25       0.959627  0.919515  \n",
       "26       0.957447  0.934626  \n",
       "27       0.932258  0.860308  \n",
       "28       0.978852  0.950071  \n",
       "29       0.925926  0.893382  \n",
       "30       0.788845  0.644448  \n",
       "31       0.863924  0.837950  \n",
       "32       0.900641  0.842464  \n",
       "33       0.615635  0.686267  \n",
       "34       0.429851  0.589021  \n",
       "35       0.783784  0.852603  \n",
       "36       0.723602  0.795154  \n",
       "37       0.537994  0.676008  \n",
       "38       0.496774  0.611610  \n",
       "39       0.764350  0.834702  \n",
       "40       0.549383  0.671451  \n",
       "41       0.366534  0.443430  \n",
       "42       0.398734  0.532019  \n",
       "43       0.464744  0.587617  \n",
       "44       0.928339  0.854726  \n",
       "45       0.994030  0.975046  \n",
       "46       0.981982  0.960323  \n",
       "47       0.981366  0.918039  \n",
       "48       0.969605  0.936812  \n",
       "49       0.974194  0.874737  \n",
       "50       0.984894  0.958027  \n",
       "51       0.962963  0.912017  \n",
       "52       0.876494  0.667592  \n",
       "53       0.924051  0.867197  \n",
       "54       0.932692  0.851025  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados_modelo_metricas_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
